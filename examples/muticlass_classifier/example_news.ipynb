{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"news_exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_prompt = \"\"\"\n",
    "You goal is to classify the following news headlines into one of the following categories:\n",
    "1- World\n",
    "2- Sports\n",
    "3- Business\n",
    "4- Sci/Tech\n",
    "\n",
    "Provide your response as a JSON dictionary with the following structure:\n",
    "{\n",
    "    \"chain_of_thought\": \"Your step-by-step reasoning here\",\n",
    "    \"topic\": \"The identified topic - the ONLY possible topics are \"World\", \"Sports\", \"Business\", \"Sci/Tech\". Output just one single category.\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output format prompt\n",
    "output_format_prompt = \"\"\"\n",
    "Provide your response as a JSON dictionary with the following structure:\n",
    "{\n",
    "    \"chain_of_thought\": \"Your step-by-step reasoning here\",\n",
    "    \"topic\": \"The identified topic - the ONLY possible topics are \"World\", \"Sports\", \"Business\", \"Sci/Tech\". Output just one single category.\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output schema\n",
    "output_schema = {\n",
    "    'key_to_extract': 'topic',\n",
    "    'value_mapping': {\n",
    "        'World': 'World',\n",
    "        'Sports': 'Sports',\n",
    "        'Business': 'Business',\n",
    "        'Sci/Tech': 'Sci/Tech',\n",
    "    },\n",
    "    'regex_pattern': r'\"topic\":\\s*\"([^\"]+)\"',  # Changed from \\w+ to [^\"]+ to capture everything until the closing quote\n",
    "    #\n",
    "    'chain_of_thought_key': 'chain_of_thought',  \n",
    "    'chain_of_thought_regex': r'\"chain_of_thought\":\\s*\"(.*?)\"',\n",
    "    #\n",
    "    'use_json_mode': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of optimization iterations\n",
    "iterations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model providers and models for evaluation and optimization\n",
    "eval_provider = \"openai\"\n",
    "eval_model = \"gpt-4o-mini\"\n",
    "optim_provider = \"openai\"\n",
    "optim_model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the CSV file containing review data for evaluation\n",
    "eval_datapath = \"news.csv\"\n",
    "text_column = \"Title\"\n",
    "target_column = \"topic\"\n",
    "sample_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to sys.path\n",
    "# Use getcwd() to get the current working directory for Jupyter notebooks\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "sys.path.append(grandparent_dir)\n",
    "from src.iterative_prompt_optimization import optimize_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fears for T N pension after talks</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>Around the world</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>Void is filled with Clement</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>Martinez leaves bitter</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>5 of arthritis patients in Singapore take Bext...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>EBay gets into rentals</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     label\n",
       "0                     Fears for T N pension after talks  Business\n",
       "1     The Race is On: Second Private Team Sets Launc...  Sci/Tech\n",
       "2         Ky. Company Wins Grant to Study Peptides (AP)  Sci/Tech\n",
       "3         Prediction Unit Helps Forecast Wildfires (AP)  Sci/Tech\n",
       "4           Calif. Aims to Limit Farm-Related Smog (AP)  Sci/Tech\n",
       "...                                                 ...       ...\n",
       "7595                                   Around the world     World\n",
       "7596                        Void is filled with Clement    Sports\n",
       "7597                             Martinez leaves bitter    Sports\n",
       "7598  5 of arthritis patients in Singapore take Bext...  Business\n",
       "7599                             EBay gets into rentals  Business\n",
       "\n",
       "[7600 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "eval_data = pd.read_csv(eval_datapath, encoding='ISO-8859-1', usecols=[text_column, target_column])\n",
    "eval_data = eval_data.rename(columns={text_column: 'text', target_column: 'label'})\n",
    "eval_data[\"text\"] = eval_data[\"text\"].astype(str)\n",
    "eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation data shape: (20, 2)\n",
      "                                                text     label\n",
      "0  Ford: Monthly Sales Drop, Company Looks To New...  Business\n",
      "1          Scores of Iraqis die in 3 days of attacks     World\n",
      "2  Large Explosion Heard in Central Baghdad (Reut...     World\n",
      "3                       United #39;s pension dilemma  Business\n",
      "4                    Media center at your fingertips  Sci/Tech\n"
     ]
    }
   ],
   "source": [
    "# Randomly select n samples from each class\n",
    "eval_data = (\n",
    "    eval_data.groupby('label')\n",
    "    .apply(lambda x: x.sample(n=sample_size, random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "# Shuffle the DataFrame randomly\n",
    "eval_data = eval_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(f\"Evaluation data shape: {eval_data.shape}\")\n",
    "print(eval_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected problem type: multiclass\n",
      "Selected evaluation provider: openai\n",
      "Selected evaluation model: gpt-4o-mini\n",
      "Evaluation temperature: 0.7\n",
      "Selected optimization provider: openai\n",
      "Selected optimization model: gpt-4o-mini\n",
      "Optimization temperature: 0\n",
      "Estimated token usage: 45600\n",
      "Estimated cost: $0.05\n",
      "\n",
      "Do you want to proceed with the optimization? (Y/N): \n",
      "Iteration 1/5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────────── Current Full Prompt ──────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> You goal is to classify the following news headlines into one of the following categories:                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> 1- World                                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> 2- Sports                                                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> 3- Business                                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> 4- Sci/Tech                                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Provide your response as a JSON dictionary with the following structure:                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> {                                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>     \"chain_of_thought\": \"Your step-by-step reasoning here\",                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>     \"topic\": \"The identified topic - the ONLY possible topics are \"World\", \"Sports\", \"Business\", \"Sci/Tech\".    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Output just one single category.\"                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> }                                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m Current Full Prompt \u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m You goal is to classify the following news headlines into one of the following categories:                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m 1- World                                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m 2- Sports                                                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m 3- Business                                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m 4- Sci/Tech                                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Provide your response as a JSON dictionary with the following structure:                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m {                                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m     \"chain_of_thought\": \"Your step-by-step reasoning here\",                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m     \"topic\": \"The identified topic - the ONLY possible topics are \"World\", \"Sports\", \"Business\", \"Sci/Tech\".    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Output just one single category.\"                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m }                                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Processing text 1/20 .....\n",
      "Using cached output for text 1/20\n",
      "Prediction 1/20: Business | Ground Truth: Business ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 2/20 .....\n",
      "Using cached output for text 2/20\n",
      "Prediction 2/20: World | Ground Truth: World ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 3/20 .....\n",
      "Using cached output for text 3/20\n",
      "Prediction 3/20: World | Ground Truth: World ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 4/20 .....\n",
      "Using cached output for text 4/20\n",
      "Prediction 4/20: Business | Ground Truth: Business ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 5/20 .....\n",
      "Using cached output for text 5/20\n",
      "Prediction 5/20: Sci/Tech | Ground Truth: Sci/Tech ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 6/20 .....\n",
      "Using cached output for text 6/20\n",
      "Prediction 6/20: World | Ground Truth: Sci/Tech ❌ (Incorrect)\n",
      "-----------------------------------\n",
      "Processing text 7/20 .....\n",
      "Using cached output for text 7/20\n",
      "Prediction 7/20: Sports | Ground Truth: Sports ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 8/20 .....\n",
      "Using cached output for text 8/20\n",
      "Prediction 8/20: Business | Ground Truth: Business ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 9/20 .....\n",
      "Using cached output for text 9/20\n",
      "Prediction 9/20: World | Ground Truth: World ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 10/20 .....\n",
      "Using cached output for text 10/20\n",
      "Prediction 10/20: World | Ground Truth: World ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 11/20 .....\n",
      "Using cached output for text 11/20\n",
      "Prediction 11/20: Sports | Ground Truth: Sports ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 12/20 .....\n",
      "Using cached output for text 12/20\n",
      "Prediction 12/20: Business | Ground Truth: Business ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 13/20 .....\n",
      "Using cached output for text 13/20\n",
      "Prediction 13/20: Sci/Tech | Ground Truth: Sci/Tech ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 14/20 .....\n",
      "Using cached output for text 14/20\n",
      "Prediction 14/20: World | Ground Truth: World ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 15/20 .....\n",
      "Using cached output for text 15/20\n",
      "Prediction 15/20: Business | Ground Truth: Business ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 16/20 .....\n",
      "Using cached output for text 16/20\n",
      "Prediction 16/20: Sports | Ground Truth: Sports ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 17/20 .....\n",
      "Using cached output for text 17/20\n",
      "Prediction 17/20: Sci/Tech | Ground Truth: Sci/Tech ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 18/20 .....\n",
      "Using cached output for text 18/20\n",
      "Prediction 18/20: Sports | Ground Truth: Sports ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 19/20 .....\n",
      "Using cached output for text 19/20\n",
      "Prediction 19/20: Sports | Ground Truth: Sports ✅ (Correct)\n",
      "-----------------------------------\n",
      "Processing text 20/20 .....\n",
      "Using cached output for text 20/20\n",
      "Prediction 20/20: Sci/Tech | Ground Truth: Sci/Tech ✅ (Correct)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 1</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.9583 │\n",
       "│ Recall              │ 0.9500 │\n",
       "│ Accuracy            │ 0.9500 │\n",
       "│ F1-score            │ 0.9495 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├─────────────────────┼────────┤\n",
       "│ Valid Predictions   │     20 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 1\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.9583 │\n",
       "│ Recall              │ 0.9500 │\n",
       "│ Accuracy            │ 0.9500 │\n",
       "│ F1-score            │ 0.9495 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m                   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m      \u001b[0m\u001b[2m \u001b[0m│\n",
       "├─────────────────────┼────────┤\n",
       "│ Valid Predictions   │     20 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">       Confusion Matrix        </span>\n",
       "┏━━━━━━━━━━━━━┳━━━┳━━━┳━━━┳━━━┓\n",
       "┃<span style=\"font-weight: bold\"> True↓/Pred→ </span>┃<span style=\"font-weight: bold\"> 0 </span>┃<span style=\"font-weight: bold\"> 1 </span>┃<span style=\"font-weight: bold\"> 2 </span>┃<span style=\"font-weight: bold\"> 3 </span>┃\n",
       "┡━━━━━━━━━━━━━╇━━━╇━━━╇━━━╇━━━┩\n",
       "│ 0           │ <span style=\"font-weight: bold\">5</span> │ 0 │ 0 │ 0 │\n",
       "├─────────────┼───┼───┼───┼───┤\n",
       "│ 1           │ 0 │ <span style=\"font-weight: bold\">4</span> │ 0 │ 1 │\n",
       "├─────────────┼───┼───┼───┼───┤\n",
       "│ 2           │ 0 │ 0 │ <span style=\"font-weight: bold\">5</span> │ 0 │\n",
       "├─────────────┼───┼───┼───┼───┤\n",
       "│ 3           │ 0 │ 0 │ 0 │ <span style=\"font-weight: bold\">5</span> │\n",
       "└─────────────┴───┴───┴───┴───┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m       Confusion Matrix        \u001b[0m\n",
       "┏━━━━━━━━━━━━━┳━━━┳━━━┳━━━┳━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTrue↓/Pred→\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m0\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m1\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m2\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m3\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━╇━━━╇━━━╇━━━╇━━━┩\n",
       "│ 0           │ \u001b[1m5\u001b[0m │ 0 │ 0 │ 0 │\n",
       "├─────────────┼───┼───┼───┼───┤\n",
       "│ 1           │ 0 │ \u001b[1m4\u001b[0m │ 0 │ 1 │\n",
       "├─────────────┼───┼───┼───┼───┤\n",
       "│ 2           │ 0 │ 0 │ \u001b[1m5\u001b[0m │ 0 │\n",
       "├─────────────┼───┼───┼───┼───┤\n",
       "│ 3           │ 0 │ 0 │ 0 │ \u001b[1m5\u001b[0m │\n",
       "└─────────────┴───┴───┴───┴───┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Analyzing predictions for multiclass classification...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run the prompt optimization process\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m best_prompt, best_metrics \u001b[38;5;241m=\u001b[39m optimize_prompt(\n\u001b[1;32m      3\u001b[0m     initial_prompt \u001b[38;5;241m=\u001b[39m initial_prompt,\n\u001b[1;32m      4\u001b[0m     eval_data \u001b[38;5;241m=\u001b[39m eval_data,\n\u001b[1;32m      5\u001b[0m     iterations \u001b[38;5;241m=\u001b[39miterations,\n\u001b[1;32m      6\u001b[0m     eval_provider\u001b[38;5;241m=\u001b[39meval_provider,\n\u001b[1;32m      7\u001b[0m     eval_model\u001b[38;5;241m=\u001b[39meval_model,\n\u001b[1;32m      8\u001b[0m     eval_temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m      9\u001b[0m     optim_provider\u001b[38;5;241m=\u001b[39moptim_provider,\n\u001b[1;32m     10\u001b[0m     optim_model\u001b[38;5;241m=\u001b[39moptim_model,\n\u001b[1;32m     11\u001b[0m     optim_temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     12\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m     output_format_prompt \u001b[38;5;241m=\u001b[39m output_format_prompt,\n\u001b[1;32m     14\u001b[0m     output_schema\u001b[38;5;241m=\u001b[39moutput_schema,\n\u001b[1;32m     15\u001b[0m     fp_comments \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     fn_comments \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     tp_comments \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     invalid_comments\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m     validation_comments\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     experiment_name \u001b[38;5;241m=\u001b[39m experiment_name,\n\u001b[1;32m     21\u001b[0m     skip_prompt_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/AI-Prompt-Optimiser/src/iterative_prompt_optimization/optimize.py:171\u001b[0m, in \u001b[0;36moptimize_prompt\u001b[0;34m(initial_prompt, output_format_prompt, eval_data, iterations, eval_provider, eval_model, eval_temperature, optim_provider, optim_model, optim_temperature, output_schema, use_cache, fp_comments, fn_comments, tp_comments, invalid_comments, validation_comments, prompt_engineering_comments, experiment_name, skip_prompt_validation)\u001b[0m\n\u001b[1;32m    151\u001b[0m     new_prompt, analyses, prompts_used \u001b[38;5;241m=\u001b[39m generate_new_prompt(\n\u001b[1;32m    152\u001b[0m         current_prompt,\n\u001b[1;32m    153\u001b[0m         output_format_prompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m         prompt_engineering_comments\u001b[38;5;241m=\u001b[39mprompt_engineering_comments\n\u001b[1;32m    169\u001b[0m     )\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# problem_type == \"multiclass\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m     new_prompt, analyses, prompts_used \u001b[38;5;241m=\u001b[39m generate_new_prompt_multiclass(\n\u001b[1;32m    172\u001b[0m         initial_prompt\u001b[38;5;241m=\u001b[39mcurrent_prompt,\n\u001b[1;32m    173\u001b[0m         output_format_prompt\u001b[38;5;241m=\u001b[39moutput_format_prompt,\n\u001b[1;32m    174\u001b[0m         results\u001b[38;5;241m=\u001b[39mresults,\n\u001b[1;32m    175\u001b[0m         previous_metrics\u001b[38;5;241m=\u001b[39mprevious_metrics,\n\u001b[1;32m    176\u001b[0m         log_dir\u001b[38;5;241m=\u001b[39mlog_dir,\n\u001b[1;32m    177\u001b[0m         iteration\u001b[38;5;241m=\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    178\u001b[0m         provider\u001b[38;5;241m=\u001b[39moptim_provider,\n\u001b[1;32m    179\u001b[0m         model\u001b[38;5;241m=\u001b[39moptim_model,\n\u001b[1;32m    180\u001b[0m         temperature\u001b[38;5;241m=\u001b[39moptim_temperature,\n\u001b[1;32m    181\u001b[0m         correct_comments\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    182\u001b[0m         incorrect_comments\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    183\u001b[0m         prompt_engineering_comments\u001b[38;5;241m=\u001b[39mprompt_engineering_comments\n\u001b[1;32m    184\u001b[0m     )\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# Add analyses and prompts used to results\u001b[39;00m\n\u001b[1;32m    187\u001b[0m results\u001b[38;5;241m.\u001b[39mupdate(analyses)\n",
      "File \u001b[0;32m~/Documents/GitHub/AI-Prompt-Optimiser/src/iterative_prompt_optimization/prompt_generation_multiclass.py:146\u001b[0m, in \u001b[0;36mgenerate_new_prompt_multiclass\u001b[0;34m(initial_prompt, output_format_prompt, results, previous_metrics, log_dir, iteration, provider, model, temperature, correct_comments, incorrect_comments, prompt_engineering_comments)\u001b[0m\n\u001b[1;32m    134\u001b[0m     incorrect_percentage \u001b[38;5;241m=\u001b[39m (num_incorrect \u001b[38;5;241m/\u001b[39m total_predictions) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m    136\u001b[0m     incorrect_prompt \u001b[38;5;241m=\u001b[39m INCORRECT_PREDICTIONS_ANALYSIS_PROMPT\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    137\u001b[0m         initial_prompt\u001b[38;5;241m=\u001b[39minitial_prompt,\n\u001b[1;32m    138\u001b[0m         incorrect_texts_and_cot\u001b[38;5;241m=\u001b[39mincorrect_texts_and_cot,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m         incorrect_comments\u001b[38;5;241m=\u001b[39mincorrect_comments\n\u001b[1;32m    144\u001b[0m     )\n\u001b[0;32m--> 146\u001b[0m     incorrect_analysis \u001b[38;5;241m=\u001b[39m get_analysis(provider, model, temperature, incorrect_prompt)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     incorrect_analysis \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo incorrect predictions found in this iteration.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/AI-Prompt-Optimiser/src/iterative_prompt_optimization/model_interface.py:191\u001b[0m, in \u001b[0;36mget_analysis\u001b[0;34m(provider, model, temperature, analysis_prompt)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_ollama_analysis(model, analysis_prompt, temperature)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m provider \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_openai_analysis(model, analysis_prompt, temperature)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m provider \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manthropic\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_anthropic_analysis(model, analysis_prompt, temperature)\n",
      "File \u001b[0;32m~/Documents/GitHub/AI-Prompt-Optimiser/src/iterative_prompt_optimization/model_interface.py:231\u001b[0m, in \u001b[0;36m_get_openai_analysis\u001b[0;34m(model, analysis_prompt, temperature)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_openai_analysis\u001b[39m(model: \u001b[38;5;28mstr\u001b[39m, analysis_prompt: \u001b[38;5;28mstr\u001b[39m, temperature: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    230\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper function to get analysis from OpenAI models.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m     client \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[1;32m    232\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    233\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    234\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m         temperature\u001b[38;5;241m=\u001b[39mtemperature\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_client.py:123\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.openai.com/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    124\u001b[0m     version\u001b[38;5;241m=\u001b[39m__version__,\n\u001b[1;32m    125\u001b[0m     base_url\u001b[38;5;241m=\u001b[39mbase_url,\n\u001b[1;32m    126\u001b[0m     max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[1;32m    127\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    128\u001b[0m     http_client\u001b[38;5;241m=\u001b[39mhttp_client,\n\u001b[1;32m    129\u001b[0m     custom_headers\u001b[38;5;241m=\u001b[39mdefault_headers,\n\u001b[1;32m    130\u001b[0m     custom_query\u001b[38;5;241m=\u001b[39mdefault_query,\n\u001b[1;32m    131\u001b[0m     _strict_response_validation\u001b[38;5;241m=\u001b[39m_strict_response_validation,\n\u001b[1;32m    132\u001b[0m )\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_stream_cls \u001b[38;5;241m=\u001b[39m Stream\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletions \u001b[38;5;241m=\u001b[39m resources\u001b[38;5;241m.\u001b[39mCompletions(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:849\u001b[0m, in \u001b[0;36mSyncAPIClient.__init__\u001b[0;34m(self, version, base_url, max_retries, timeout, transport, proxies, limits, http_client, custom_headers, custom_query, _strict_response_validation)\u001b[0m\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid `http_client` argument; Expected an instance of `httpx.Client` but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(http_client)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    834\u001b[0m     )\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    837\u001b[0m     version\u001b[38;5;241m=\u001b[39mversion,\n\u001b[1;32m    838\u001b[0m     limits\u001b[38;5;241m=\u001b[39mlimits,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    847\u001b[0m     _strict_response_validation\u001b[38;5;241m=\u001b[39m_strict_response_validation,\n\u001b[1;32m    848\u001b[0m )\n\u001b[0;32m--> 849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m http_client \u001b[38;5;129;01mor\u001b[39;00m SyncHttpxClientWrapper(\n\u001b[1;32m    850\u001b[0m     base_url\u001b[38;5;241m=\u001b[39mbase_url,\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;66;03m# cast to a valid type because mypy doesn't understand our type narrowing\u001b[39;00m\n\u001b[1;32m    852\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mcast(Timeout, timeout),\n\u001b[1;32m    853\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    854\u001b[0m     transport\u001b[38;5;241m=\u001b[39mtransport,\n\u001b[1;32m    855\u001b[0m     limits\u001b[38;5;241m=\u001b[39mlimits,\n\u001b[1;32m    856\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    857\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:747\u001b[0m, in \u001b[0;36m_DefaultHttpxClient.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    745\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimits\u001b[39m\u001b[38;5;124m\"\u001b[39m, DEFAULT_CONNECTION_LIMITS)\n\u001b[1;32m    746\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 747\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_client.py:685\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, auth, params, headers, cookies, verify, cert, http1, http2, proxies, mounts, timeout, follow_redirects, limits, max_redirects, event_hooks, base_url, transport, app, trust_env, default_encoding)\u001b[0m\n\u001b[1;32m    670\u001b[0m proxy_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_proxy_map(proxies, allow_env_proxies)\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_transport(\n\u001b[1;32m    673\u001b[0m     verify\u001b[38;5;241m=\u001b[39mverify,\n\u001b[1;32m    674\u001b[0m     cert\u001b[38;5;241m=\u001b[39mcert,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    680\u001b[0m     trust_env\u001b[38;5;241m=\u001b[39mtrust_env,\n\u001b[1;32m    681\u001b[0m )\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mounts: typing\u001b[38;5;241m.\u001b[39mDict[URLPattern, typing\u001b[38;5;241m.\u001b[39mOptional[BaseTransport]] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    683\u001b[0m     URLPattern(key): \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proxy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_proxy_transport(\n\u001b[1;32m    686\u001b[0m         proxy,\n\u001b[1;32m    687\u001b[0m         verify\u001b[38;5;241m=\u001b[39mverify,\n\u001b[1;32m    688\u001b[0m         cert\u001b[38;5;241m=\u001b[39mcert,\n\u001b[1;32m    689\u001b[0m         http1\u001b[38;5;241m=\u001b[39mhttp1,\n\u001b[1;32m    690\u001b[0m         http2\u001b[38;5;241m=\u001b[39mhttp2,\n\u001b[1;32m    691\u001b[0m         limits\u001b[38;5;241m=\u001b[39mlimits,\n\u001b[1;32m    692\u001b[0m         trust_env\u001b[38;5;241m=\u001b[39mtrust_env,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, proxy \u001b[38;5;129;01min\u001b[39;00m proxy_map\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    695\u001b[0m }\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mounts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mounts\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    698\u001b[0m         {URLPattern(key): transport \u001b[38;5;28;01mfor\u001b[39;00m key, transport \u001b[38;5;129;01min\u001b[39;00m mounts\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    699\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_client.py:739\u001b[0m, in \u001b[0;36mClient._init_proxy_transport\u001b[0;34m(self, proxy, verify, cert, http1, http2, limits, trust_env)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_proxy_transport\u001b[39m(\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    731\u001b[0m     proxy: Proxy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    737\u001b[0m     trust_env: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    738\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseTransport:\n\u001b[0;32m--> 739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m HTTPTransport(\n\u001b[1;32m    740\u001b[0m         verify\u001b[38;5;241m=\u001b[39mverify,\n\u001b[1;32m    741\u001b[0m         cert\u001b[38;5;241m=\u001b[39mcert,\n\u001b[1;32m    742\u001b[0m         http1\u001b[38;5;241m=\u001b[39mhttp1,\n\u001b[1;32m    743\u001b[0m         http2\u001b[38;5;241m=\u001b[39mhttp2,\n\u001b[1;32m    744\u001b[0m         limits\u001b[38;5;241m=\u001b[39mlimits,\n\u001b[1;32m    745\u001b[0m         trust_env\u001b[38;5;241m=\u001b[39mtrust_env,\n\u001b[1;32m    746\u001b[0m         proxy\u001b[38;5;241m=\u001b[39mproxy,\n\u001b[1;32m    747\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_transports/default.py:133\u001b[0m, in \u001b[0;36mHTTPTransport.__init__\u001b[0;34m(self, verify, cert, http1, http2, limits, trust_env, proxy, uds, local_address, retries, socket_options)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    121\u001b[0m     verify: VerifyTypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m     socket_options: typing\u001b[38;5;241m.\u001b[39mOptional[typing\u001b[38;5;241m.\u001b[39mIterable[SOCKET_OPTION]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    132\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m     ssl_context \u001b[38;5;241m=\u001b[39m create_ssl_context(verify\u001b[38;5;241m=\u001b[39mverify, cert\u001b[38;5;241m=\u001b[39mcert, trust_env\u001b[38;5;241m=\u001b[39mtrust_env)\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proxy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mConnectionPool(\n\u001b[1;32m    137\u001b[0m             ssl_context\u001b[38;5;241m=\u001b[39mssl_context,\n\u001b[1;32m    138\u001b[0m             max_connections\u001b[38;5;241m=\u001b[39mlimits\u001b[38;5;241m.\u001b[39mmax_connections,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m             socket_options\u001b[38;5;241m=\u001b[39msocket_options,\n\u001b[1;32m    147\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_config.py:51\u001b[0m, in \u001b[0;36mcreate_ssl_context\u001b[0;34m(cert, verify, trust_env, http2)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_ssl_context\u001b[39m(\n\u001b[1;32m     46\u001b[0m     cert: typing\u001b[38;5;241m.\u001b[39mOptional[CertTypes] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m     verify: VerifyTypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m     trust_env: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m     http2: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     50\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLContext:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLConfig(\n\u001b[1;32m     52\u001b[0m         cert\u001b[38;5;241m=\u001b[39mcert, verify\u001b[38;5;241m=\u001b[39mverify, trust_env\u001b[38;5;241m=\u001b[39mtrust_env, http2\u001b[38;5;241m=\u001b[39mhttp2\n\u001b[1;32m     53\u001b[0m     )\u001b[38;5;241m.\u001b[39mssl_context\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_config.py:75\u001b[0m, in \u001b[0;36mSSLConfig.__init__\u001b[0;34m(self, cert, verify, trust_env, http2)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrust_env \u001b[38;5;241m=\u001b[39m trust_env\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp2 \u001b[38;5;241m=\u001b[39m http2\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_ssl_context()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_config.py:87\u001b[0m, in \u001b[0;36mSSLConfig.load_ssl_context\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_ssl_context verify=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m cert=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m trust_env=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m http2=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp2,\n\u001b[1;32m     84\u001b[0m )\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_ssl_context_verify()\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_ssl_context_no_verify()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_config.py:142\u001b[0m, in \u001b[0;36mSSLConfig.load_ssl_context_verify\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ca_bundle_path\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[1;32m    143\u001b[0m     cafile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(ca_bundle_path)\n\u001b[1;32m    144\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_verify_locations cafile=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, cafile)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/pathlib.py:892\u001b[0m, in \u001b[0;36mPath.is_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;124;03mWhether this path is a regular file (also True for symlinks pointing\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;124;03mto regular files).\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m S_ISREG(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstat()\u001b[38;5;241m.\u001b[39mst_mode)\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _ignore_error(e):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/pathlib.py:840\u001b[0m, in \u001b[0;36mPath.stat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, follow_symlinks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    836\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;124;03m    Return the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;124;03m    os.stat() does.\u001b[39;00m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 840\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mstat(\u001b[38;5;28mself\u001b[39m, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the prompt optimization process\n",
    "best_prompt, best_metrics = optimize_prompt(\n",
    "    initial_prompt = initial_prompt,\n",
    "    eval_data = eval_data,\n",
    "    iterations =iterations,\n",
    "    eval_provider=eval_provider,\n",
    "    eval_model=eval_model,\n",
    "    eval_temperature=0.7,\n",
    "    optim_provider=optim_provider,\n",
    "    optim_model=optim_model,\n",
    "    optim_temperature=0,\n",
    "    use_cache=True,\n",
    "    output_format_prompt = output_format_prompt,\n",
    "    output_schema=output_schema,\n",
    "    fp_comments = \"\",\n",
    "    fn_comments = \"\",\n",
    "    tp_comments = \"\",\n",
    "    invalid_comments=\"\",\n",
    "    validation_comments=\"\",\n",
    "    experiment_name = experiment_name,\n",
    "    skip_prompt_validation = True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
