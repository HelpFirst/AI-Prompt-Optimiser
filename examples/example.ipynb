{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define initial prompt and output format\n",
    "# initial_prompt = (\n",
    "#     \"Please look for the following risk factor: Is the client at risk of self-harm? For instance, do they mention suicidal thoughts or ideation? Do they imply they might do physical damage to themselves or to property? Do they reference wanting to 'end it all or say it's 'not worth living'? Please output: 1. risk_type: // suicidality, 2. risk_output: // 'risk present' : this means there is evidence this risk is present in the case 'risk not present' : there is evidence the risk is NOT present or there is no evidence whether the case contains that risk or not. (If in doubt, it is better to err on the side of caution and say 'risk present') 3. explanation: // State words/terms that indicate the reason the risk_output was chosen. Be brief in your explanation. State facts found in the text, do not infer. E.g. 'Client expressed suicidal ideation'. Leave blank for 'risk not present.'\"\n",
    "# )\n",
    "\n",
    "# output_format_prompt = (\n",
    "#     \"Output should be STRICT JSON, containing: dictionary containing the type of risk with their output and explanation, formatted like this: {'risk_type': 'suicidality', 'risk_output': str, 'explanation': str}'\"\n",
    "# )\n",
    "\n",
    "initial_prompt = (\n",
    "        \"You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment. \"\n",
    "        \"Respond with '1' if it is positive, or '0' if it is negative.\"\n",
    "    )\n",
    "\n",
    "# Output format prompt\n",
    "output_format_prompt = (\n",
    "    \"You are to act as a binary responder. For every question asked, reply strictly with '1' for positive or '0' for negative. \"\n",
    "    \"Do NOT include any additional text or explanation.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define output schema\n",
    "# output_schema = {\n",
    "#     'key_to_extract': 'risk_output',\n",
    "#     'value_mapping': {\n",
    "#         'risk_present': 1,\n",
    "#         'risk_not_present': 0\n",
    "#     },\n",
    "#     'regex_pattern': r'\"risk_output\":\\s*\"(.*?)\"'\n",
    "# }\n",
    "\n",
    "output_schema = {\n",
    "    'key_to_extract': None,  # Set to None for direct output\n",
    "    'value_mapping': None,   # Set to None for direct mapping\n",
    "    'regex_pattern': r'^(0|1)$',  # Match the entire output for binary classification\n",
    "    'use_json_mode': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of optimization iterations\n",
    "iterations = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model providers and models for evaluation and optimization\n",
    "eval_provider = \"ollama\"\n",
    "eval_model = \"llama3.1\"\n",
    "optim_provider = \"ollama\"\n",
    "optim_model = \"llama3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the CSV file containing review data for evaluation\n",
    "eval_datapath = \"reviews.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to sys.path\n",
    "# Use getcwd() to get the current working directory for Jupyter notebooks\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "from src.iterative_prompt_optimization import optimize_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation data shape: (10, 2)\n",
      "                                                text  label\n",
      "0  Was this based on a comic-book? A video-game? ...      1\n",
      "1  If you ask me the first one was really better ...      0\n",
      "2  When I was a kid, I loved \"Tiny Toons\". I espe...      1\n",
      "3  I hate guns and have never murdered anyone, bu...      0\n",
      "4  I do not have much to say than this is a great...      1\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "eval_data = pd.read_csv(eval_datapath, encoding='ISO-8859-1', usecols=['Text', 'Sentiment'])\n",
    "eval_data.columns = ['text', 'label']\n",
    "# Randomly select 50 positive and 50 negative samples\n",
    "eval_data = (\n",
    "    eval_data.groupby('label')\n",
    "    .apply(lambda x: x.sample(n=5, random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "# Shuffle the DataFrame randomly\n",
    "eval_data = eval_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(f\"Evaluation data shape: {eval_data.shape}\")\n",
    "print(eval_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected evaluation provider: ollama\n",
      "Selected evaluation model: llama3.1\n",
      "Selected optimization provider: ollama\n",
      "Selected optimization model: llama3.1\n",
      "Estimated token usage: 107190\n",
      "Estimated cost: $0 API Costs - Running on Local Hardware\n",
      "\n",
      "Do you want to proceed with the optimization? (Y/N): \n",
      "Iteration 1/3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────────── Current Full Prompt ──────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Respond with '1' if it is positive, or '0' if it is negative.                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> You are to act as a binary responder. For every question asked, reply strictly with '1' for positive or '0' for <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> negative. Do NOT include any additional text or explanation.                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m Current Full Prompt \u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Respond with '1' if it is positive, or '0' if it is negative.                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m You are to act as a binary responder. For every question asked, reply strictly with '1' for positive or '0' for \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m negative. Do NOT include any additional text or explanation.                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 1/10\n",
      "Prediction 1/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 2/10\n",
      "Prediction 2/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 3/10\n",
      "Prediction 3/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 4/10\n",
      "Prediction 4/10: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 5/10\n",
      "Prediction 5/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 6/10\n",
      "Prediction 6/10: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 7/10\n",
      "Prediction 7/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 8/10\n",
      "Prediction 8/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 9/10\n",
      "Prediction 9/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 10/10\n",
      "Prediction 10/10: 1 | Ground Truth: 1 ✅ (TP)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 1</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.7143 │\n",
       "│ Recall              │ 1.0000 │\n",
       "│ Accuracy            │ 0.8000 │\n",
       "│ F1-score            │ 0.8333 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 1\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.7143 │\n",
       "│ Recall              │ 1.0000 │\n",
       "│ Accuracy            │ 0.8000 │\n",
       "│ F1-score            │ 0.8333 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing misclassifications...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭──────────────────────────────────────── Analysis of Misclassifications ─────────────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> After analyzing the misclassifications, I've identified specific examples from each set where the model made a  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> mistake and highlighted what elements of the text may have led to the incorrect classification.                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Negative (0) texts incorrectly classified as positive:**                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. The first example starts with a strong negative sentiment towards guns and violence (\"I hate guns...\"), but  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> then suddenly shifts to a more positive tone when discussing the movie \"Shuttle\". The model misinterprets this  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> shift as a genuine positive opinion about the film.                                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> What led to the error: The text's initial strong negative sentiment is quickly followed by a description of a   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> violent act, which might have caused the model to temporarily overlook the negative context and focus on the    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> positive aspects of the movie. However, this positive tone is short-lived and doesn't necessarily reflect the   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> overall opinion about the film.                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. The second example starts with a clear statement that the movie \"Dragon Hunt\" is \"one of the cheapest action <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> flicks of the eighties\" and describes it as \"really awful.\" However, the text also mentions that it's a great   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> party tape, which might have led the model to misinterpret this as a positive review.                           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> What led to the error: The phrase \"great party tape\" can be seen as an oxymoron, implying that the movie is     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> enjoyable in a low-brow or ironic way. This ambiguity might have caused the model to overlook the negative      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> context and focus on the potential enjoyment of the film.                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Positives (1) texts incorrectly classified as negative:**                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> None were provided.                                                                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> However, based on my analysis of the misclassifications, I'd like to propose strategies to improve the          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> classification prompt:                                                                                          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Contextual understanding:** The model should be able to understand the context in which a statement is     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> made, including any subsequent or preceding statements that might influence its interpretation.                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Nuanced sentiment detection:** The prompt should be designed to detect subtle nuances in sentiment, such   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> as when a positive statement is followed by a negative one (as seen in example 1).                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Idiomatic expression handling:** Idioms like \"great party tape\" can be tricky for models to interpret. The <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> prompt could benefit from better handling of idiomatic expressions that might convey contradictory sentiments.  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Increased sensitivity:** To reduce false negatives, the model should be made more sensitive to subtle      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> positive sentiments or neutral statements that don't necessarily imply a strong negative opinion.               <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> To achieve these improvements, I recommend:                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Expanded training data:** Incorporate a broader range of texts with nuanced sentiment expressions and      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> idiomatic language.                                                                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Fine-tuned models:** Adjust the model's architecture or fine-tune its weights to better capture contextual <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> understanding, nuanced sentiment detection, and idiomatic expression handling.                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Regular evaluation and feedback:** Continuously evaluate the model's performance on diverse datasets and   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> incorporate user feedback to refine its accuracy.                                                               <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> By addressing these areas of improvement, you can develop a more accurate classification prompt that better     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> recognizes subtle differences in text sentiment, reducing both false positives and false negatives.             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m───────────────────────────────────────\u001b[0m\u001b[1m Analysis of Misclassifications \u001b[0m\u001b[1m────────────────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m After analyzing the misclassifications, I've identified specific examples from each set where the model made a  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m mistake and highlighted what elements of the text may have led to the incorrect classification.                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Negative (0) texts incorrectly classified as positive:**                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. The first example starts with a strong negative sentiment towards guns and violence (\"I hate guns...\"), but  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m then suddenly shifts to a more positive tone when discussing the movie \"Shuttle\". The model misinterprets this  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m shift as a genuine positive opinion about the film.                                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m What led to the error: The text's initial strong negative sentiment is quickly followed by a description of a   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m violent act, which might have caused the model to temporarily overlook the negative context and focus on the    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m positive aspects of the movie. However, this positive tone is short-lived and doesn't necessarily reflect the   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m overall opinion about the film.                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. The second example starts with a clear statement that the movie \"Dragon Hunt\" is \"one of the cheapest action \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m flicks of the eighties\" and describes it as \"really awful.\" However, the text also mentions that it's a great   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m party tape, which might have led the model to misinterpret this as a positive review.                           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m What led to the error: The phrase \"great party tape\" can be seen as an oxymoron, implying that the movie is     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m enjoyable in a low-brow or ironic way. This ambiguity might have caused the model to overlook the negative      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m context and focus on the potential enjoyment of the film.                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Positives (1) texts incorrectly classified as negative:**                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m None were provided.                                                                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m However, based on my analysis of the misclassifications, I'd like to propose strategies to improve the          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m classification prompt:                                                                                          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Contextual understanding:** The model should be able to understand the context in which a statement is     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m made, including any subsequent or preceding statements that might influence its interpretation.                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Nuanced sentiment detection:** The prompt should be designed to detect subtle nuances in sentiment, such   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m as when a positive statement is followed by a negative one (as seen in example 1).                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Idiomatic expression handling:** Idioms like \"great party tape\" can be tricky for models to interpret. The \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m prompt could benefit from better handling of idiomatic expressions that might convey contradictory sentiments.  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Increased sensitivity:** To reduce false negatives, the model should be made more sensitive to subtle      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m positive sentiments or neutral statements that don't necessarily imply a strong negative opinion.               \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m To achieve these improvements, I recommend:                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Expanded training data:** Incorporate a broader range of texts with nuanced sentiment expressions and      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m idiomatic language.                                                                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Fine-tuned models:** Adjust the model's architecture or fine-tune its weights to better capture contextual \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m understanding, nuanced sentiment detection, and idiomatic expression handling.                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Regular evaluation and feedback:** Continuously evaluate the model's performance on diverse datasets and   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m incorporate user feedback to refine its accuracy.                                                               \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m By addressing these areas of improvement, you can develop a more accurate classification prompt that better     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m recognizes subtle differences in text sentiment, reducing both false positives and false negatives.             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating new prompt...\n",
      "\n",
      "Iteration 2/3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────────── Current Full Prompt ──────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Here's the revised prompt:                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> \"I am looking for nuanced sentiment in the provided text. Please determine whether it expresses a generally     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> positive opinion (1) or a generally negative opinion (0), taking into account context, subtleties, and          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> idiomatic expressions that might influence its interpretation.\"                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> You are to act as a binary responder. For every question asked, reply strictly with '1' for positive or '0' for <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> negative. Do NOT include any additional text or explanation.                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m Current Full Prompt \u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m Here's the revised prompt:                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \"I am looking for nuanced sentiment in the provided text. Please determine whether it expresses a generally     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m positive opinion (1) or a generally negative opinion (0), taking into account context, subtleties, and          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m idiomatic expressions that might influence its interpretation.\"                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m You are to act as a binary responder. For every question asked, reply strictly with '1' for positive or '0' for \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m negative. Do NOT include any additional text or explanation.                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 1/10\n",
      "Prediction 1/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 2/10\n",
      "Prediction 2/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 3/10\n",
      "Prediction 3/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 4/10\n",
      "Prediction 4/10: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 5/10\n",
      "Prediction 5/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 6/10\n",
      "Prediction 6/10: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 7/10\n",
      "Prediction 7/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 8/10\n",
      "Prediction 8/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 9/10\n",
      "Prediction 9/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 10/10\n",
      "Prediction 10/10: 1 | Ground Truth: 1 ✅ (TP)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 2</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.7143 │\n",
       "│ Recall              │ 1.0000 │\n",
       "│ Accuracy            │ 0.8000 │\n",
       "│ F1-score            │ 0.8333 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 2\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.7143 │\n",
       "│ Recall              │ 1.0000 │\n",
       "│ Accuracy            │ 0.8000 │\n",
       "│ F1-score            │ 0.8333 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing misclassifications...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭──────────────────────────────────────── Analysis of Misclassifications ─────────────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> After analyzing the misclassifications, I've identified specific examples where the model made mistakes and     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> highlighted elements of the text that may have led to the incorrect classification.                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Negative (0) texts incorrectly classified as positive:**                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **\"Shuttle\" movie review**: The model incorrectly classified this text as a positive review.                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         * Mistake: The text contains phrases like \"I think even God would say, 'Good call.'\" and \"'Hostel'-type <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> film,\" which might have led the model to assume the reviewer found the movie enjoyable despite some flaws.      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> However, the overall tone is still critical, and the reviewer mentions several negative aspects.                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         * Correct classification: Negative review                                                               <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **\"Dragon Hunt\" movie review**: The model incorrectly classified this text as a positive review.             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         * Mistake: The text contains phrases like \"one of the cheapest action flicks of the eighties,\" \"great   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> trash,\" and \"really awful.\" These statements might have led the model to overlook the overall negative tone,    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> focusing only on the phrase \"great party tape!\"                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         * Correct classification: Negative review                                                               <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Positives (0) texts incorrectly classified as negative:**                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> (Note: There were no positive texts provided in the second set.)                                                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> To improve the classification prompt and reduce both false positives and false negatives, I recommend the       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> following strategies:                                                                                           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Tone analysis**: Incorporate more advanced tone analysis techniques to better capture subtle nuances in    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> text sentiment. This could involve using machine learning models specifically designed for tone detection or    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> incorporating emotional intelligence scores.                                                                    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Contextual understanding**: Train the model to consider context when classifying text. For example, in the <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> case of the \"Shuttle\" review, the model should have taken into account the reviewer's criticism of the movie's  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> flaws despite finding it enjoyable overall.                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Phrasal emphasis**: Use phrasal emphasis to determine the primary focus of a sentence or paragraph. In the <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> case of the \"Dragon Hunt\" review, the phrase \"great party tape!\" might have been emphasized as the main         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> takeaway, while the negative statements were downplayed.                                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Sentiment intensity analysis**: Incorporate sentiment intensity analysis to capture the strength and       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> nuance of emotions expressed in text. This would allow the model to better distinguish between strong positive  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> or negative feelings versus more subtle or mixed emotions.                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 5. **Training data diversification**: Increase the diversity of training data to include a broader range of     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> text styles, genres, and topics. This would help the model become more robust and less prone to misclassifying  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> certain types of texts.                                                                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 6. **Regular fine-tuning**: Regularly retrain the model on new data and fine-tune its performance using active  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> learning techniques or human evaluation. This would enable the model to adapt to evolving language patterns and <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> improve overall classification accuracy.                                                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> By implementing these strategies, the model can become more sensitive to subtle differences in text sentiment   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> and reduce both false positives and false negatives.                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m───────────────────────────────────────\u001b[0m\u001b[1m Analysis of Misclassifications \u001b[0m\u001b[1m────────────────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m After analyzing the misclassifications, I've identified specific examples where the model made mistakes and     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m highlighted elements of the text that may have led to the incorrect classification.                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Negative (0) texts incorrectly classified as positive:**                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **\"Shuttle\" movie review**: The model incorrectly classified this text as a positive review.                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         * Mistake: The text contains phrases like \"I think even God would say, 'Good call.'\" and \"'Hostel'-type \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m film,\" which might have led the model to assume the reviewer found the movie enjoyable despite some flaws.      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m However, the overall tone is still critical, and the reviewer mentions several negative aspects.                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         * Correct classification: Negative review                                                               \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **\"Dragon Hunt\" movie review**: The model incorrectly classified this text as a positive review.             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         * Mistake: The text contains phrases like \"one of the cheapest action flicks of the eighties,\" \"great   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m trash,\" and \"really awful.\" These statements might have led the model to overlook the overall negative tone,    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m focusing only on the phrase \"great party tape!\"                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         * Correct classification: Negative review                                                               \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Positives (0) texts incorrectly classified as negative:**                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m (Note: There were no positive texts provided in the second set.)                                                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m To improve the classification prompt and reduce both false positives and false negatives, I recommend the       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m following strategies:                                                                                           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Tone analysis**: Incorporate more advanced tone analysis techniques to better capture subtle nuances in    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m text sentiment. This could involve using machine learning models specifically designed for tone detection or    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m incorporating emotional intelligence scores.                                                                    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Contextual understanding**: Train the model to consider context when classifying text. For example, in the \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m case of the \"Shuttle\" review, the model should have taken into account the reviewer's criticism of the movie's  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m flaws despite finding it enjoyable overall.                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Phrasal emphasis**: Use phrasal emphasis to determine the primary focus of a sentence or paragraph. In the \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m case of the \"Dragon Hunt\" review, the phrase \"great party tape!\" might have been emphasized as the main         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m takeaway, while the negative statements were downplayed.                                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Sentiment intensity analysis**: Incorporate sentiment intensity analysis to capture the strength and       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m nuance of emotions expressed in text. This would allow the model to better distinguish between strong positive  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m or negative feelings versus more subtle or mixed emotions.                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 5. **Training data diversification**: Increase the diversity of training data to include a broader range of     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m text styles, genres, and topics. This would help the model become more robust and less prone to misclassifying  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m certain types of texts.                                                                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 6. **Regular fine-tuning**: Regularly retrain the model on new data and fine-tune its performance using active  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m learning techniques or human evaluation. This would enable the model to adapt to evolving language patterns and \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m improve overall classification accuracy.                                                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m By implementing these strategies, the model can become more sensitive to subtle differences in text sentiment   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m and reduce both false positives and false negatives.                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating new prompt...\n",
      "\n",
      "Iteration 3/3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────────── Current Full Prompt ──────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Here's the revised prompt:                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> \"I'm looking for nuanced sentiment in the provided text, considering context, phrasal emphasis, and subtleties  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> like idiomatic expressions. Please determine whether it expresses a generally positive opinion (1), a generally <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> negative opinion (0), or a more ambiguous stance, taking into account both explicit statements and implied      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> attitudes.\"                                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> You are to act as a binary responder. For every question asked, reply strictly with '1' for positive or '0' for <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> negative. Do NOT include any additional text or explanation.                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m Current Full Prompt \u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m Here's the revised prompt:                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \"I'm looking for nuanced sentiment in the provided text, considering context, phrasal emphasis, and subtleties  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m like idiomatic expressions. Please determine whether it expresses a generally positive opinion (1), a generally \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m negative opinion (0), or a more ambiguous stance, taking into account both explicit statements and implied      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m attitudes.\"                                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m You are to act as a binary responder. For every question asked, reply strictly with '1' for positive or '0' for \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m negative. Do NOT include any additional text or explanation.                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 1/10\n",
      "Prediction 1/10: 0 | Ground Truth: 1 ❌ (FN)\n",
      "Processing text 2/10\n",
      "Prediction 2/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 3/10\n",
      "Prediction 3/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 4/10\n",
      "Prediction 4/10: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 5/10\n",
      "Prediction 5/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 6/10\n",
      "Prediction 6/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 7/10\n",
      "Prediction 7/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 8/10\n",
      "Prediction 8/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 9/10\n",
      "Prediction 9/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 10/10\n",
      "Prediction 10/10: 1 | Ground Truth: 1 ✅ (TP)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 3</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.8000 │\n",
       "│ Recall              │ 0.8000 │\n",
       "│ Accuracy            │ 0.8000 │\n",
       "│ F1-score            │ 0.8000 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 3\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.8000 │\n",
       "│ Recall              │ 0.8000 │\n",
       "│ Accuracy            │ 0.8000 │\n",
       "│ F1-score            │ 0.8000 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────╮\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Best Prompt:</span> │\n",
       "╰──────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────╮\n",
       "│ \u001b[1;32mBest Prompt:\u001b[0m │\n",
       "╰──────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment. \n",
       "Respond with <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span> if it is positive, or <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span> if it is negative.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment. \n",
       "Respond with \u001b[32m'1'\u001b[0m if it is positive, or \u001b[32m'0'\u001b[0m if it is negative.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────────────────╮\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Output Format:</span> │\n",
       "╰────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭────────────────╮\n",
       "│ \u001b[1;32mOutput Format:\u001b[0m │\n",
       "╰────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You are to act as a binary responder. For every question asked, reply strictly with <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span> for positive or <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span> for \n",
       "negative. Do NOT include any additional text or explanation.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "You are to act as a binary responder. For every question asked, reply strictly with \u001b[32m'1'\u001b[0m for positive or \u001b[32m'0'\u001b[0m for \n",
       "negative. Do NOT include any additional text or explanation.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                         Comparison of All Iterations                         </span>\n",
       "┏━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Iteration </span>┃<span style=\"font-weight: bold\"> Precision </span>┃<span style=\"font-weight: bold\"> Recall </span>┃<span style=\"font-weight: bold\"> Accuracy </span>┃<span style=\"font-weight: bold\"> F1-score </span>┃<span style=\"font-weight: bold\"> Invalid Predictions </span>┃\n",
       "┡━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│     1     │    0.7143 │ <span style=\"font-weight: bold\">1.0000</span> │   <span style=\"font-weight: bold\">0.8000</span> │   <span style=\"font-weight: bold\">0.8333</span> │              <span style=\"font-weight: bold\">0.0000</span> │\n",
       "│     2     │    0.7143 │ <span style=\"font-weight: bold\">1.0000</span> │   <span style=\"font-weight: bold\">0.8000</span> │   <span style=\"font-weight: bold\">0.8333</span> │              <span style=\"font-weight: bold\">0.0000</span> │\n",
       "│     3     │    <span style=\"font-weight: bold\">0.8000</span> │ 0.8000 │   <span style=\"font-weight: bold\">0.8000</span> │   0.8000 │              <span style=\"font-weight: bold\">0.0000</span> │\n",
       "└───────────┴───────────┴────────┴──────────┴──────────┴─────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                         Comparison of All Iterations                         \u001b[0m\n",
       "┏━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mIteration\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPrecision\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mRecall\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mAccuracy\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mF1-score\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mInvalid Predictions\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│     1     │    0.7143 │ \u001b[1m1.0000\u001b[0m │   \u001b[1m0.8000\u001b[0m │   \u001b[1m0.8333\u001b[0m │              \u001b[1m0.0000\u001b[0m │\n",
       "│     2     │    0.7143 │ \u001b[1m1.0000\u001b[0m │   \u001b[1m0.8000\u001b[0m │   \u001b[1m0.8333\u001b[0m │              \u001b[1m0.0000\u001b[0m │\n",
       "│     3     │    \u001b[1m0.8000\u001b[0m │ 0.8000 │   \u001b[1m0.8000\u001b[0m │   0.8000 │              \u001b[1m0.0000\u001b[0m │\n",
       "└───────────┴───────────┴────────┴──────────┴──────────┴─────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All logs saved in directory: /Users/danielfiuzadosil/Documents/GitHub/AI-Prompt-Optimiser/runs/prompt_optimization_logs_20240925_195224\n"
     ]
    }
   ],
   "source": [
    "# Run the prompt optimization process\n",
    "best_prompt, best_metrics = optimize_prompt(\n",
    "    initial_prompt,\n",
    "    output_format_prompt,\n",
    "    eval_data,\n",
    "    iterations,\n",
    "    eval_provider=eval_provider,\n",
    "    eval_model=eval_model,\n",
    "    optim_provider=optim_provider,\n",
    "    optim_model=optim_model,\n",
    "    output_schema=output_schema\n",
    ")\n",
    "# After running the optimization process, you can analyze the results by checking \n",
    "# the generated log files in the `runs/prompt_optimization_logs_YYYYMMDD_HHMMSS` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
