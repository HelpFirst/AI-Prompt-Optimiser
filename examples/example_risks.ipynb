{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial prompt and output format\n",
    "initial_prompt = (\n",
    "    \"Please look for the following risk factor: Is the client at risk of self-harm? For instance, do they mention suicidal thoughts or ideation? Do they imply they might do physical damage to themselves or to property? Do they reference wanting to 'end it all' or say it's 'not worth living'? Provide a step-by-step chain of thought in your analysis. Please output: 1. risk_type: // suicidality, 2. chain_of_thought: // Provide your step-by-step reasoning process. 3. risk_output: // 'risk present' : this means there is evidence this risk is present in the case 'risk not present' : there is evidence the risk is NOT present or there is no evidence whether the case contains that risk or not. (If in doubt, it is better to err on the side of caution and say 'risk present') 4. explanation: // State words/terms that indicate the reason the risk_output was chosen. Be brief in your explanation. State facts found in the text, do not infer. E.g. 'Client expressed suicidal ideation'. Leave blank for 'risk not present.'\"\n",
    ")\n",
    "\n",
    "output_format_prompt = (\n",
    "    \"Output should be STRICT JSON, containing: dictionary containing the type of risk, chain of thought, output, and explanation, formatted like this: {'risk_type': 'suicidality', 'chain_of_thought': str, 'risk_output': str, 'explanation': str}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_analysis_comments = '''\n",
    "Make sure the output is a STRICT JSON following the format {'risk_type': 'suicidality', 'risk_output': str, 'explanation': str}\n",
    "The only option for risk_type is \"sucidality\", do not create a new key.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output schema\n",
    "output_schema = {\n",
    "    'key_to_extract': 'risk_output',\n",
    "    'value_mapping': {\n",
    "        'risk_present': 1,\n",
    "        'risk_not_present': 0\n",
    "    },\n",
    "    'regex_pattern': r'\"risk_output\":\\s*\"(.*?)\"',\n",
    "    'chain_of_thought_key': 'chain_of_thought',  \n",
    "    'chain_of_thought_regex': r'\"chain_of_thought\":\\s*\"(.*?)\"',\n",
    "    'use_json_mode': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of optimization iterations\n",
    "iterations = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model providers and models for evaluation and optimization\n",
    "eval_provider = \"ollama\"\n",
    "eval_model = \"llama3.1\"\n",
    "optim_provider = \"ollama\"\n",
    "optim_model = \"llama3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the CSV file containing review data for evaluation\n",
    "eval_datapath = \"risks.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to sys.path\n",
    "# Use getcwd() to get the current working directory for Jupyter notebooks\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "from src.iterative_prompt_optimization import optimize_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation data shape: (20, 2)\n",
      "                                                text  label\n",
      "0  Good afternoon <person>, I refer to the compla...      0\n",
      "1  C said to <supplier> yesterday that she wishes...      1\n",
      "2  Health concerns - consumer has mental health i...      1\n",
      "3  Please confirm if the final balance on the acc...      0\n",
      "4  I am writing to request a status update on the...      0\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "eval_data = pd.read_csv(eval_datapath, encoding='ISO-8859-1', usecols=['text', 'label'])\n",
    "# Randomly select 50 positive and 50 negative samples\n",
    "eval_data = (\n",
    "    eval_data.groupby('label')\n",
    "    .apply(lambda x: x.sample(n=10, random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "# Shuffle the DataFrame randomly\n",
    "eval_data = eval_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(f\"Evaluation data shape: {eval_data.shape}\")\n",
    "print(eval_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected evaluation provider: ollama\n",
      "Selected evaluation model: llama3.1\n",
      "Evaluation temperature: 0.7\n",
      "Selected optimization provider: ollama\n",
      "Selected optimization model: llama3.1\n",
      "Optimization temperature: 0\n",
      "Estimated token usage: 51600\n",
      "Estimated cost: $0 API Costs - Running on Local Hardware\n",
      "\n",
      "Do you want to proceed with the optimization? (Y/N): \n",
      "Iteration 1/3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────────── Current Full Prompt ──────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Please look for the following risk factor: Is the client at risk of self-harm? For instance, do they mention    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> suicidal thoughts or ideation? Do they imply they might do physical damage to themselves or to property? Do     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> they reference wanting to 'end it all' or say it's 'not worth living'? Provide a step-by-step chain of thought  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> in your analysis. Please output: 1. risk_type: // suicidality, 2. chain_of_thought: // Provide your             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> step-by-step reasoning process. 3. risk_output: // 'risk present' : this means there is evidence this risk is   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> present in the case 'risk not present' : there is evidence the risk is NOT present or there is no evidence      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> whether the case contains that risk or not. (If in doubt, it is better to err on the side of caution and say    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> 'risk present') 4. explanation: // State words/terms that indicate the reason the risk_output was chosen. Be    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> brief in your explanation. State facts found in the text, do not infer. E.g. 'Client expressed suicidal         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> ideation'. Leave blank for 'risk not present.'                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Output should be STRICT JSON, containing: dictionary containing the type of risk, chain of thought, output, and <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> explanation, formatted like this: {'risk_type': 'suicidality', 'chain_of_thought': str, 'risk_output': str,     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> 'explanation': str}                                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m Current Full Prompt \u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m Please look for the following risk factor: Is the client at risk of self-harm? For instance, do they mention    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m suicidal thoughts or ideation? Do they imply they might do physical damage to themselves or to property? Do     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m they reference wanting to 'end it all' or say it's 'not worth living'? Provide a step-by-step chain of thought  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m in your analysis. Please output: 1. risk_type: // suicidality, 2. chain_of_thought: // Provide your             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m step-by-step reasoning process. 3. risk_output: // 'risk present' : this means there is evidence this risk is   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m present in the case 'risk not present' : there is evidence the risk is NOT present or there is no evidence      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m whether the case contains that risk or not. (If in doubt, it is better to err on the side of caution and say    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m 'risk present') 4. explanation: // State words/terms that indicate the reason the risk_output was chosen. Be    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m brief in your explanation. State facts found in the text, do not infer. E.g. 'Client expressed suicidal         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m ideation'. Leave blank for 'risk not present.'                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Output should be STRICT JSON, containing: dictionary containing the type of risk, chain of thought, output, and \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m explanation, formatted like this: {'risk_type': 'suicidality', 'chain_of_thought': str, 'risk_output': str,     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m 'explanation': str}                                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 1/20\n",
      "Using cached output for text 1/20\n",
      "Prediction 1/20: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 2/20\n",
      "Using cached output for text 2/20\n",
      "Prediction 2/20: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 3/20\n",
      "Using cached output for text 3/20\n",
      "Prediction 3/20: 0 | Ground Truth: 1 ❌ (FN)\n",
      "Processing text 4/20\n",
      "Using cached output for text 4/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "All parsing methods failed!\n",
      "Prediction 4/20: None | Ground Truth: 0 🛠️ (Invalid Output Format) - Raw output: This conversation just started. I am ready to assist you with a risk analysis. What is the client's text or statement that we can analyze for the presence of self-harm risk?\n",
      "Processing text 5/20\n",
      "Using cached output for text 5/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "All parsing methods failed!\n",
      "Prediction 5/20: None | Ground Truth: 0 🛠️ (Invalid Output Format) - Raw output: It seems you're looking for a status update on an issue, but I don't have any context or information about this specific case. You asked me to analyze a potential risk of self-harm, which I was happy to do.To clarify, since we didn't actually discuss a real case, let's just say that the analysis is still pending. If you'd like to provide some text related to a client or situation where you're concerned about self-harm, I can help walk through the steps of identifying this risk factor and provide a response in the format you requested.Would you like to proceed with an example case?\n",
      "Processing text 6/20\n",
      "Using cached output for text 6/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "Prediction 6/20: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 7/20\n",
      "Using cached output for text 7/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "Prediction 7/20: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 8/20\n",
      "Using cached output for text 8/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "Prediction 8/20: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 9/20\n",
      "Using cached output for text 9/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "Failed to parse JSON-like structure\n",
      "Trying regex extraction...\n",
      "Prediction 9/20: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 10/20\n",
      "Using cached output for text 10/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "Prediction 10/20: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 11/20\n",
      "Using cached output for text 11/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "Prediction 11/20: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 12/20\n",
      "Using cached output for text 12/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "All parsing methods failed!\n",
      "Prediction 12/20: None | Ground Truth: 0 🛠️ (Invalid Output Format) - Raw output: I'd be happy to provide a complimentary output as a token of goodwill.Please go ahead and provide the text for analysis, and I'll generate the output as per your request.If you'd like, I can also simulate some example text related to the risk factor in question (i.e., self-harm) so we can test the output together. Just let me know!\n",
      "Processing text 13/20\n",
      "Using cached output for text 13/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "All parsing methods failed!\n",
      "Prediction 13/20: None | Ground Truth: 0 🛠️ (Invalid Output Format) - Raw output: It seems we're not actually discussing a case or risk assessment at all. We've been pretending to analyze a hypothetical scenario.If that's the case, let's start fresh! Would you like to simulate a risk assessment for a fictional client? I can respond with a step-by-step chain of thought and output as if we were analyzing an actual case. Just let me know what kind of scenario you'd like us to explore (e.g., mental health issue, criminal behavior, etc.).\n",
      "Processing text 14/20\n",
      "Using cached output for text 14/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "Prediction 14/20: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 15/20\n",
      "Using cached output for text 15/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "All parsing methods failed!\n",
      "Prediction 15/20: None | Ground Truth: 0 🛠️ (Invalid Output Format) - Raw output: It seems you were providing context for a hypothetical scenario where a risk assessment needs to be performed on a client. However, I'll proceed with the analysis as requested.Please go ahead and provide the text that describes the client's situation, and I will analyze it step-by-step to determine if there is a risk of self-harm or suicidality.Once you're ready, please paste the text, and I'll output the result in the specified JSON format.\n",
      "Processing text 16/20\n",
      "Using cached output for text 16/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "Prediction 16/20: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 17/20\n",
      "Using cached output for text 17/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "All parsing methods failed!\n",
      "Prediction 17/20: None | Ground Truth: 0 🛠️ (Invalid Output Format) - Raw output: It seems there's been a misunderstanding. This conversation has just begun, and no case or information has been provided yet. If you'd like to discuss a specific scenario or provide some text for analysis, I'm here to help. Please feel free to share the context or details you'd like me to examine regarding the risk factor of self-harm.\n",
      "Processing text 18/20\n",
      "Using cached output for text 18/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "Prediction 18/20: 0 | Ground Truth: 1 ❌ (FN)\n",
      "Processing text 19/20\n",
      "Using cached output for text 19/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "Prediction 19/20: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 20/20\n",
      "Using cached output for text 20/20\n",
      "Python literal evaluation failed...\n",
      "Trying JSON parsing...\n",
      "JSON parsing failed...\n",
      "Trying JSON-like structure extraction...\n",
      "All parsing methods failed!\n",
      "Prediction 20/20: None | Ground Truth: 0 🛠️ (Invalid Output Format) - Raw output: You initially asked me to analyze a text for the risk factor of self-harm and provide a step-by-step chain of thought. However, you didn't provide any text for analysis.If you'd like to proceed, please provide the text or context you'd like me to analyze, and I'll be happy to assist you with the following:1. `risk_type`: The type of risk factor identified (e.g., suicidality)2. `chain_of_thought`: A step-by-step reasoning process for my analysis3. `risk_output`: An output indicating whether the risk is present or not present4. `explanation`: A brief explanation for the chosen output, citing specific text or facts from your input.Please provide the necessary context, and I'll do my best to assist you!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 1</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 1.0000 │\n",
       "│ Recall              │ 0.8000 │\n",
       "│ Accuracy            │ 0.8462 │\n",
       "│ F1-score            │ 0.8889 │\n",
       "│ Valid Predictions   │     13 │\n",
       "│ Invalid Predictions │      7 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 1\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 1.0000 │\n",
       "│ Recall              │ 0.8000 │\n",
       "│ Accuracy            │ 0.8462 │\n",
       "│ F1-score            │ 0.8889 │\n",
       "│ Valid Predictions   │     13 │\n",
       "│ Invalid Predictions │      7 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing misclassifications, true positives, and invalid outputs...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭───────── False Positives Analysis ──────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> No false positives found in this iteration. <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m────────\u001b[0m\u001b[1m False Positives Analysis \u001b[0m\u001b[1m─────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m No false positives found in this iteration. \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the prompt optimization process\n",
    "best_prompt, best_metrics = optimize_prompt(\n",
    "    initial_prompt = initial_prompt,\n",
    "    output_format_prompt = output_format_prompt,\n",
    "    eval_data = eval_data,\n",
    "    iterations =iterations,\n",
    "    eval_provider=eval_provider,\n",
    "    eval_model=eval_model,\n",
    "    eval_temperature=0.7,\n",
    "    optim_provider=optim_provider,\n",
    "    optim_model=optim_model,\n",
    "    optim_temperature=0,\n",
    "    output_schema=output_schema,\n",
    "    use_cache=True,  # Set to False if you want to disable caching,\n",
    "    fp_comments = \"\",\n",
    "    fn_comments = \"\",\n",
    "    tp_comments = \"\",\n",
    "    invalid_comments=invalid_analysis_comments,\n",
    "    validation_comments=\"\",\n",
    ")\n",
    "# After running the optimization process, you can analyze the results by checking \n",
    "# the generated log files in the `runs/prompt_optimization_logs_YYYYMMDD_HHMMSS` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
