{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial prompt and output format\n",
    "initial_prompt = (\n",
    "    \"Please look for the following risk factor: Is the client at risk of self-harm? For instance, do they mention suicidal thoughts or ideation? Do they imply they might do physical damage to themselves or to property? Do they reference wanting to 'end it all or say it's 'not worth living'? Please output: 1. risk_type: // suicidality, 2. risk_output: // 'risk present' : this means there is evidence this risk is present in the case 'risk not present' : there is evidence the risk is NOT present or there is no evidence whether the case contains that risk or not. (If in doubt, it is better to err on the side of caution and say 'risk present') 3. explanation: // State words/terms that indicate the reason the risk_output was chosen. Be brief in your explanation. State facts found in the text, do not infer. E.g. 'Client expressed suicidal ideation'. Leave blank for 'risk not present.'\"\n",
    ")\n",
    "\n",
    "output_format_prompt = (\n",
    "    \"Output should be STRICT JSON, containing: dictionary containing the type of risk with their output and explanation, formatted like this: {'risk_type': 'suicidality', 'risk_output': str, 'explanation': str}'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output schema\n",
    "output_schema = {\n",
    "    'key_to_extract': 'risk_output',\n",
    "    'value_mapping': {\n",
    "        'risk_present': 1,\n",
    "        'risk_not_present': 0\n",
    "    },\n",
    "    'regex_pattern': r'\"risk_output\":\\s*\"(.*?)\"'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of optimization iterations\n",
    "iterations = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model providers and models for evaluation and optimization\n",
    "eval_provider = \"ollama\"\n",
    "eval_model = \"llama3.1\"\n",
    "optim_provider = \"ollama\"\n",
    "optim_model = \"llama3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the CSV file containing review data for evaluation\n",
    "eval_datapath = \"risks.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to sys.path\n",
    "# Use getcwd() to get the current working directory for Jupyter notebooks\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "from src.iterative_prompt_optimization import optimize_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation data shape: (10, 2)\n",
      "                                                text  label\n",
      "0            Consumer had suicide attempt in January      1\n",
      "1  Please confirm if the final balance on the acc...      0\n",
      "2  Illness/Disability: C has , depression, anxiet...      1\n",
      "3  Good afternoon <person>, I refer to the compla...      0\n",
      "4  C stated they are feeling hopeless and don't k...      1\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "eval_data = pd.read_csv(eval_datapath, encoding='ISO-8859-1', usecols=['text', 'label'])\n",
    "# Randomly select 50 positive and 50 negative samples\n",
    "eval_data = (\n",
    "    eval_data.groupby('label')\n",
    "    .apply(lambda x: x.sample(n=5, random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "# Shuffle the DataFrame randomly\n",
    "eval_data = eval_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(f\"Evaluation data shape: {eval_data.shape}\")\n",
    "print(eval_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected evaluation provider: ollama\n",
      "Selected evaluation model: llama3.1\n",
      "Selected optimization provider: ollama\n",
      "Selected optimization model: llama3.1\n",
      "Estimated token usage: 21810\n",
      "Estimated cost: $0 API Costs - Running on Local Hardware\n",
      "\n",
      "Do you want to proceed with the optimization? (Y/N): \n",
      "Iteration 1/3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────────── Current Full Prompt ──────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Please look for the following risk factor: Is the client at risk of self-harm? For instance, do they mention    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> suicidal thoughts or ideation? Do they imply they might do physical damage to themselves or to property? Do     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> they reference wanting to 'end it all or say it's 'not worth living'? Please output: 1. risk_type: //           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> suicidality, 2. risk_output: // 'risk present' : this means there is evidence this risk is present in the case  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> 'risk not present' : there is evidence the risk is NOT present or there is no evidence whether the case         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> contains that risk or not. (If in doubt, it is better to err on the side of caution and say 'risk present') 3.  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> explanation: // State words/terms that indicate the reason the risk_output was chosen. Be brief in your         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> explanation. State facts found in the text, do not infer. E.g. 'Client expressed suicidal ideation'. Leave      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> blank for 'risk not present.'                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Output should be STRICT JSON, containing: dictionary containing the type of risk with their output and          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> explanation, formatted like this: {'risk_type': 'suicidality', 'risk_output': str, 'explanation': str}'         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m Current Full Prompt \u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m Please look for the following risk factor: Is the client at risk of self-harm? For instance, do they mention    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m suicidal thoughts or ideation? Do they imply they might do physical damage to themselves or to property? Do     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m they reference wanting to 'end it all or say it's 'not worth living'? Please output: 1. risk_type: //           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m suicidality, 2. risk_output: // 'risk present' : this means there is evidence this risk is present in the case  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m 'risk not present' : there is evidence the risk is NOT present or there is no evidence whether the case         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m contains that risk or not. (If in doubt, it is better to err on the side of caution and say 'risk present') 3.  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m explanation: // State words/terms that indicate the reason the risk_output was chosen. Be brief in your         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m explanation. State facts found in the text, do not infer. E.g. 'Client expressed suicidal ideation'. Leave      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m blank for 'risk not present.'                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Output should be STRICT JSON, containing: dictionary containing the type of risk with their output and          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m explanation, formatted like this: {'risk_type': 'suicidality', 'risk_output': str, 'explanation': str}'         \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 1/10\n",
      "Prediction 1/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 2/10\n",
      "Unable to find risk_output in the raw output\n",
      "Prediction 2/10: None | Ground Truth: 0 🛠️ (Invalid Output Format)\n",
      "Processing text 3/10\n",
      "Prediction 3/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 4/10\n",
      "Prediction 4/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 5/10\n",
      "Prediction 5/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 6/10\n",
      "Unable to find risk_output in the raw output\n",
      "Prediction 6/10: None | Ground Truth: 0 🛠️ (Invalid Output Format)\n",
      "Processing text 7/10\n",
      "Prediction 7/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 8/10\n",
      "Unable to find risk_output in the raw output\n",
      "Prediction 8/10: None | Ground Truth: 0 🛠️ (Invalid Output Format)\n",
      "Processing text 9/10\n",
      "Prediction 9/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 10/10\n",
      "Prediction 10/10: 1 | Ground Truth: 1 ✅ (TP)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 1</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 1.0000 │\n",
       "│ Recall              │ 1.0000 │\n",
       "│ Accuracy            │ 1.0000 │\n",
       "│ F1-score            │ 1.0000 │\n",
       "│ Invalid Predictions │      3 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 1\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 1.0000 │\n",
       "│ Recall              │ 1.0000 │\n",
       "│ Accuracy            │ 1.0000 │\n",
       "│ F1-score            │ 1.0000 │\n",
       "│ Invalid Predictions │      3 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing misclassifications...\n"
     ]
    }
   ],
   "source": [
    "# Run the prompt optimization process\n",
    "best_prompt, best_metrics = optimize_prompt(\n",
    "    initial_prompt,\n",
    "    output_format_prompt,\n",
    "    eval_data,\n",
    "    iterations,\n",
    "    eval_provider=eval_provider,\n",
    "    eval_model=eval_model,\n",
    "    optim_provider=optim_provider,\n",
    "    optim_model=optim_model,\n",
    "    output_schema=output_schema\n",
    ")\n",
    "# After running the optimization process, you can analyze the results by checking \n",
    "# the generated log files in the `runs/prompt_optimization_logs_YYYYMMDD_HHMMSS` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
