{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"sentiment_exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_prompt = '''\n",
    "You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment. \n",
    "Think through your analysis step by step using chain of thought reasoning. \n",
    "After your analysis, respond with a STRIC JSON dictionary containing two keys: \n",
    "\"chain_of_thought\" (your step-by-step reasoning) and \"classification\" (1 for positive, 0 for negative).\n",
    "\n",
    "Provide your response as a JSON dictionary with the following structure:\n",
    "{\n",
    "    \"chain_of_thought\": \"Your step-by-step reasoning here\"\n",
    "    \"classification\": 0 or 1,\n",
    "}\n",
    "Ensure that \"chain_of_thought\" contains your detailed analysis, and \"classification\" is strictly 0 or 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output format prompt\n",
    "output_format_prompt = '''\n",
    "Provide your response as a JSON dictionary with the following structure:\n",
    "{\n",
    "    \"chain_of_thought\": \"Your step-by-step reasoning here\"\n",
    "    \"classification\": 0 or 1,\n",
    "}\n",
    "Ensure that \"chain_of_thought\" contains your detailed analysis, and \"classification\" is strictly 0 or 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_comments = \"\"\n",
    "fn_comments = \"\"\n",
    "tp_comments = \"\"\n",
    "invalid_comments = \"\"\n",
    "prompt_engineering_comments = \"\"\n",
    "validation_comments = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output schema\n",
    "output_schema = {\n",
    "    'key_to_extract': 'classification',\n",
    "    'value_mapping': {'1': 1,'0': 0},\n",
    "    'regex_pattern': r'\"classification\":\\s*(\\d)',\n",
    "    #\n",
    "    'chain_of_thought_key': 'chain_of_thought',  \n",
    "    'chain_of_thought_regex': r'\"chain_of_thought\":\\s*\"(.*?)\"',\n",
    "    #\n",
    "    'use_json_mode': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of optimization iterations\n",
    "iterations = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model providers and models for evaluation and optimization\n",
    "# eval_provider = \"ollama\"\n",
    "# eval_model = \"llama3.1\"\n",
    "# optim_provider = \"ollama\"\n",
    "# optim_model = \"llama3.1\"\n",
    "eval_provider = \"openai\"\n",
    "eval_model = \"gpt-4o-mini\"\n",
    "optim_provider = \"openai\"\n",
    "optim_model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the CSV file containing review data for evaluation\n",
    "eval_datapath = \"sentiments.csv\"\n",
    "sample_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to sys.path\n",
    "# Use getcwd() to get the current working directory for Jupyter notebooks\n",
    "current_dir = os.getcwd()\n",
    "grandparent_dir = os.path.dirname(os.path.dirname(current_dir))\n",
    "sys.path.append(grandparent_dir)\n",
    "from src.iterative_prompt_optimization import optimize_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation data shape: (10, 2)\n",
      "                                                text  label\n",
      "0  Was this based on a comic-book? A video-game? ...      1\n",
      "1  If you ask me the first one was really better ...      0\n",
      "2  When I was a kid, I loved \"Tiny Toons\". I espe...      1\n",
      "3  I hate guns and have never murdered anyone, bu...      0\n",
      "4  I do not have much to say than this is a great...      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/w_c5c0zs70lcg80xwzft9fjh0000gn/T/ipykernel_42759/3552288940.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=round(sample_size/2), random_state=42))\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "eval_data = pd.read_csv(eval_datapath, encoding='ISO-8859-1', usecols=['Text', 'Sentiment'])\n",
    "eval_data.columns = ['text', 'label']\n",
    "# Randomly select 50 positive and 50 negative samples\n",
    "eval_data = (\n",
    "    eval_data.groupby('label')\n",
    "    .apply(lambda x: x.sample(n=round(sample_size/2), random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "# Shuffle the DataFrame randomly\n",
    "eval_data = eval_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(f\"Evaluation data shape: {eval_data.shape}\")\n",
    "print(eval_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected problem type: binary\n",
      "Selected evaluation provider: openai\n",
      "Selected evaluation model: gpt-4o-mini\n",
      "Evaluation temperature: 0.7\n",
      "Selected optimization provider: openai\n",
      "Selected optimization model: gpt-4o-mini\n",
      "Optimization temperature: 0\n",
      "Estimated token usage: 74080\n",
      "Estimated cost: $0.09\n",
      "\n",
      "Do you want to proceed with the optimization? (Y/N): \n",
      "Iteration 1/2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭───────────────────────────────────────────── Current Full Prompt ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Think through your analysis step by step using chain of thought reasoning.                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> After your analysis, respond with a STRIC JSON dictionary containing two keys:                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> \"chain_of_thought\" (your step-by-step reasoning) and \"classification\" (1 for positive, 0 for negative).       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Provide your response as a JSON dictionary with the following structure:                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> {                                                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>     \"chain_of_thought\": \"Your step-by-step reasoning here\"                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>     \"classification\": 0 or 1,                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> }                                                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Ensure that \"chain_of_thought\" contains your detailed analysis, and \"classification\" is strictly 0 or 1       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m────────────────────────────────────────────\u001b[0m\u001b[34m Current Full Prompt \u001b[0m\u001b[34m────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Think through your analysis step by step using chain of thought reasoning.                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m After your analysis, respond with a STRIC JSON dictionary containing two keys:                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \"chain_of_thought\" (your step-by-step reasoning) and \"classification\" (1 for positive, 0 for negative).       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Provide your response as a JSON dictionary with the following structure:                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m {                                                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m     \"chain_of_thought\": \"Your step-by-step reasoning here\"                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m     \"classification\": 0 or 1,                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m }                                                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Ensure that \"chain_of_thought\" contains your detailed analysis, and \"classification\" is strictly 0 or 1       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Processing text 1/10 .....\n",
      "Using cached output for text 1/10\n",
      "Prediction 1/10: 0 | Ground Truth: 1 ❌ (FN)\n",
      "-----------------------------------\n",
      "Processing text 2/10 .....\n",
      "Using cached output for text 2/10\n",
      "Prediction 2/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "-----------------------------------\n",
      "Processing text 3/10 .....\n",
      "Using cached output for text 3/10\n",
      "Prediction 3/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "-----------------------------------\n",
      "Processing text 4/10 .....\n",
      "Using cached output for text 4/10\n",
      "Prediction 4/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "-----------------------------------\n",
      "Processing text 5/10 .....\n",
      "Using cached output for text 5/10\n",
      "Prediction 5/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "-----------------------------------\n",
      "Processing text 6/10 .....\n",
      "Using cached output for text 6/10\n",
      "Prediction 6/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "-----------------------------------\n",
      "Processing text 7/10 .....\n",
      "Using cached output for text 7/10\n",
      "Prediction 7/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "-----------------------------------\n",
      "Processing text 8/10 .....\n",
      "Using cached output for text 8/10\n",
      "Prediction 8/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "-----------------------------------\n",
      "Processing text 9/10 .....\n",
      "Using cached output for text 9/10\n",
      "Prediction 9/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "-----------------------------------\n",
      "Processing text 10/10 .....\n",
      "Using cached output for text 10/10\n",
      "Prediction 10/10: 1 | Ground Truth: 1 ✅ (TP)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 1</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 1.0000 │\n",
       "│ Recall              │ 0.8000 │\n",
       "│ Accuracy            │ 0.9000 │\n",
       "│ F1-score            │ 0.8889 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├─────────────────────┼────────┤\n",
       "│ Valid Predictions   │     10 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 1\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 1.0000 │\n",
       "│ Recall              │ 0.8000 │\n",
       "│ Accuracy            │ 0.9000 │\n",
       "│ F1-score            │ 0.8889 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m                   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m      \u001b[0m\u001b[2m \u001b[0m│\n",
       "├─────────────────────┼────────┤\n",
       "│ Valid Predictions   │     10 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">   Confusion Matrix    </span>\n",
       "┏━━━━━━━━━━━━━┳━━━┳━━━┓\n",
       "┃<span style=\"font-weight: bold\"> True↓/Pred→ </span>┃<span style=\"font-weight: bold\"> 0 </span>┃<span style=\"font-weight: bold\"> 1 </span>┃\n",
       "┡━━━━━━━━━━━━━╇━━━╇━━━┩\n",
       "│ 0           │ <span style=\"font-weight: bold\">5</span> │ 0 │\n",
       "├─────────────┼───┼───┤\n",
       "│ 1           │ 1 │ <span style=\"font-weight: bold\">4</span> │\n",
       "└─────────────┴───┴───┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m   Confusion Matrix    \u001b[0m\n",
       "┏━━━━━━━━━━━━━┳━━━┳━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTrue↓/Pred→\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m0\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m1\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━╇━━━╇━━━┩\n",
       "│ 0           │ \u001b[1m5\u001b[0m │ 0 │\n",
       "├─────────────┼───┼───┤\n",
       "│ 1           │ 1 │ \u001b[1m4\u001b[0m │\n",
       "└─────────────┴───┴───┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Analyzing misclassifications, true positives, and invalid outputs...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭───────── False Positives Analysis ──────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> No false positives found in this iteration. <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m────────\u001b[0m\u001b[1m False Positives Analysis \u001b[0m\u001b[1m─────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m No false positives found in this iteration. \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭─────────────────────────────────────────── False Negatives Analysis ────────────────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Overemphasis on Negative Language**: The chain of thought heavily focuses on the negative aspects of the   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> film, such as \"nothing to be taken seriously,\" \"dumb dialog,\" and \"awful writing.\" This leads to a              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> misclassification of the overall sentiment. To improve recall, the classifier should be trained to recognize    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> nuanced expressions of enjoyment or entertainment, even when accompanied by criticism.                          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Ambiguous Positive Phrases**: The text contains phrases like \"mindless fun at its best\" and \"exciting and  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> fun,\" which suggest some level of positive sentiment. However, the classifier may not adequately weigh these    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> phrases against the surrounding negativity. Enhancing the model's ability to identify and prioritize positive   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> sentiment phrases, even in critical contexts, could reduce false negatives.                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Contextual Sentiment Analysis**: The review mentions entertaining action sequences and a \"spectacular and  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> excellently shot hijack,\" which indicate positive sentiment. The classifier should incorporate a more           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> sophisticated contextual analysis that can differentiate between overall sentiment and specific positive        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> moments within a predominantly negative review.                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Nuanced Sentiment Detection**: The current model may lack the capability to detect mixed sentiments        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> effectively. Implementing a multi-class sentiment analysis approach that can classify texts as having mixed     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> sentiments could help in accurately capturing the complexity of reviews that contain both positive and negative <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> elements.                                                                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 5. **Training on Diverse Reviews**: The model should be trained on a wider variety of reviews, including those  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> that express mixed feelings. This would help the classifier learn to identify when a review, despite its        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> critical tone, still conveys positive sentiments about certain aspects, thereby improving its overall accuracy  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> and recall.                                                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m──────────────────────────────────────────\u001b[0m\u001b[1m False Negatives Analysis \u001b[0m\u001b[1m───────────────────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Overemphasis on Negative Language**: The chain of thought heavily focuses on the negative aspects of the   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m film, such as \"nothing to be taken seriously,\" \"dumb dialog,\" and \"awful writing.\" This leads to a              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m misclassification of the overall sentiment. To improve recall, the classifier should be trained to recognize    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m nuanced expressions of enjoyment or entertainment, even when accompanied by criticism.                          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Ambiguous Positive Phrases**: The text contains phrases like \"mindless fun at its best\" and \"exciting and  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m fun,\" which suggest some level of positive sentiment. However, the classifier may not adequately weigh these    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m phrases against the surrounding negativity. Enhancing the model's ability to identify and prioritize positive   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m sentiment phrases, even in critical contexts, could reduce false negatives.                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Contextual Sentiment Analysis**: The review mentions entertaining action sequences and a \"spectacular and  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m excellently shot hijack,\" which indicate positive sentiment. The classifier should incorporate a more           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m sophisticated contextual analysis that can differentiate between overall sentiment and specific positive        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m moments within a predominantly negative review.                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Nuanced Sentiment Detection**: The current model may lack the capability to detect mixed sentiments        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m effectively. Implementing a multi-class sentiment analysis approach that can classify texts as having mixed     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m sentiments could help in accurately capturing the complexity of reviews that contain both positive and negative \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m elements.                                                                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 5. **Training on Diverse Reviews**: The model should be trained on a wider variety of reviews, including those  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m that express mixed feelings. This would help the classifier learn to identify when a review, despite its        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m critical tone, still conveys positive sentiments about certain aspects, thereby improving its overall accuracy  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m and recall.                                                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭──────────────────────────────────────────── True Positives Analysis ────────────────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Use of Positive Language**: All true positive examples prominently feature positive language and           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> descriptors. Phrases like \"loved,\" \"great,\" \"amazing,\" and \"excellent quality\" are consistently used to convey  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> strong positive sentiments. Reinforcing the identification of such positive adjectives and adverbs in the       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> training data can enhance classification accuracy.                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Emotional Engagement**: The texts reflect a deep emotional engagement with the subject matter, whether     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> it’s nostalgia for a childhood cartoon or appreciation for a film's execution. Highlighting emotional           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> expressions and personal connections in the training data can help the model recognize sentiment more           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> effectively.                                                                                                    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **High Ratings and Recommendations**: Each true positive includes explicit ratings (e.g., \"10/10,\" \"9 out of <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 10 stars\") and recommendations, which serve as clear indicators of positive sentiment. Training the model to    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> recognize numerical ratings and recommendation phrases can improve its ability to classify sentiment            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> accurately.                                                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Contextual Understanding**: The true positives demonstrate an understanding of context, where the          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> reviewers not only express enjoyment but also provide thoughtful critiques that highlight strengths.            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Incorporating context-aware training can help the model discern nuanced sentiments beyond surface-level         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> language.                                                                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 5. **Consistency in Tone**: The overall tone of the true positives is consistently positive, with no            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> contradictory statements. Ensuring that the model is trained to detect tonal consistency can help it avoid      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> misclassifications in more complex texts where sentiment may fluctuate.                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> By focusing on these key elements, the model can be reinforced to better identify and classify positive         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> sentiments in various texts.                                                                                    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m───────────────────────────────────────────\u001b[0m\u001b[1m True Positives Analysis \u001b[0m\u001b[1m───────────────────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Use of Positive Language**: All true positive examples prominently feature positive language and           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m descriptors. Phrases like \"loved,\" \"great,\" \"amazing,\" and \"excellent quality\" are consistently used to convey  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m strong positive sentiments. Reinforcing the identification of such positive adjectives and adverbs in the       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m training data can enhance classification accuracy.                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Emotional Engagement**: The texts reflect a deep emotional engagement with the subject matter, whether     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m it’s nostalgia for a childhood cartoon or appreciation for a film's execution. Highlighting emotional           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m expressions and personal connections in the training data can help the model recognize sentiment more           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m effectively.                                                                                                    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **High Ratings and Recommendations**: Each true positive includes explicit ratings (e.g., \"10/10,\" \"9 out of \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 10 stars\") and recommendations, which serve as clear indicators of positive sentiment. Training the model to    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m recognize numerical ratings and recommendation phrases can improve its ability to classify sentiment            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m accurately.                                                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Contextual Understanding**: The true positives demonstrate an understanding of context, where the          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m reviewers not only express enjoyment but also provide thoughtful critiques that highlight strengths.            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Incorporating context-aware training can help the model discern nuanced sentiments beyond surface-level         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m language.                                                                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 5. **Consistency in Tone**: The overall tone of the true positives is consistently positive, with no            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m contradictory statements. Ensuring that the model is trained to detect tonal consistency can help it avoid      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m misclassifications in more complex texts where sentiment may fluctuate.                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m By focusing on these key elements, the model can be reinforced to better identify and classify positive         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m sentiments in various texts.                                                                                    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭───────── Invalid Outputs Analysis ──────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> No invalid outputs found in this iteration. <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m────────\u001b[0m\u001b[1m Invalid Outputs Analysis \u001b[0m\u001b[1m─────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m No invalid outputs found in this iteration. \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 0\n",
      "Number of NaN in y_true: 0\n",
      "Number of NaN in y_pred: 0\n",
      "Sample of y_pred: []\n",
      "\n",
      "Iteration 2/2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────────── Current Full Prompt ──────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Analyze the text step by step, focusing on identifying positive language, emotional engagement, high ratings,   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> and contextual understanding. Pay attention to nuanced sentiments, even in critical reviews, and recognize      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> ambiguous positive phrases. After your analysis, respond with a strict JSON dictionary containing two keys:     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> \"chain_of_thought\" (your detailed step-by-step reasoning) and \"classification\" (1 for positive, 0 for           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> negative).                                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Provide your response as a JSON dictionary with the following structure:                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> {                                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>     \"chain_of_thought\": \"Your step-by-step reasoning here\",                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>     \"classification\": 0 or 1                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> }                                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Ensure that \"chain_of_thought\" contains your comprehensive analysis, and \"classification\" is strictly 0 or 1.   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m Current Full Prompt \u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Analyze the text step by step, focusing on identifying positive language, emotional engagement, high ratings,   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m and contextual understanding. Pay attention to nuanced sentiments, even in critical reviews, and recognize      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m ambiguous positive phrases. After your analysis, respond with a strict JSON dictionary containing two keys:     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \"chain_of_thought\" (your detailed step-by-step reasoning) and \"classification\" (1 for positive, 0 for           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m negative).                                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Provide your response as a JSON dictionary with the following structure:                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m {                                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m     \"chain_of_thought\": \"Your step-by-step reasoning here\",                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m     \"classification\": 0 or 1                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m }                                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Ensure that \"chain_of_thought\" contains your comprehensive analysis, and \"classification\" is strictly 0 or 1.   \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Processing text 1/10 .....\n",
      "Prediction 1/10: 0 | Ground Truth: 1 ❌ (FN)\n",
      "-----------------------------------\n",
      "Processing text 2/10 .....\n",
      "Prediction 2/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "-----------------------------------\n",
      "Processing text 3/10 .....\n",
      "Prediction 3/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "-----------------------------------\n",
      "Processing text 4/10 .....\n",
      "Prediction 4/10: 1 | Ground Truth: 0 ❌ (FP)\n",
      "-----------------------------------\n",
      "Processing text 5/10 .....\n",
      "Prediction 5/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "-----------------------------------\n",
      "Processing text 6/10 .....\n",
      "Prediction 6/10: 1 | Ground Truth: 0 ❌ (FP)\n",
      "-----------------------------------\n",
      "Processing text 7/10 .....\n",
      "Prediction 7/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "-----------------------------------\n",
      "Processing text 8/10 .....\n",
      "Prediction 8/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "-----------------------------------\n",
      "Processing text 9/10 .....\n",
      "Prediction 9/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "-----------------------------------\n",
      "Processing text 10/10 .....\n",
      "Prediction 10/10: 1 | Ground Truth: 1 ✅ (TP)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 2</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.6667 │\n",
       "│ Recall              │ 0.8000 │\n",
       "│ Accuracy            │ 0.7000 │\n",
       "│ F1-score            │ 0.7273 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├─────────────────────┼────────┤\n",
       "│ Valid Predictions   │     10 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 2\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.6667 │\n",
       "│ Recall              │ 0.8000 │\n",
       "│ Accuracy            │ 0.7000 │\n",
       "│ F1-score            │ 0.7273 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m                   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m      \u001b[0m\u001b[2m \u001b[0m│\n",
       "├─────────────────────┼────────┤\n",
       "│ Valid Predictions   │     10 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">   Confusion Matrix    </span>\n",
       "┏━━━━━━━━━━━━━┳━━━┳━━━┓\n",
       "┃<span style=\"font-weight: bold\"> True↓/Pred→ </span>┃<span style=\"font-weight: bold\"> 0 </span>┃<span style=\"font-weight: bold\"> 1 </span>┃\n",
       "┡━━━━━━━━━━━━━╇━━━╇━━━┩\n",
       "│ 0           │ <span style=\"font-weight: bold\">3</span> │ 2 │\n",
       "├─────────────┼───┼───┤\n",
       "│ 1           │ 1 │ <span style=\"font-weight: bold\">4</span> │\n",
       "└─────────────┴───┴───┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m   Confusion Matrix    \u001b[0m\n",
       "┏━━━━━━━━━━━━━┳━━━┳━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTrue↓/Pred→\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m0\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m1\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━╇━━━╇━━━┩\n",
       "│ 0           │ \u001b[1m3\u001b[0m │ 2 │\n",
       "├─────────────┼───┼───┤\n",
       "│ 1           │ 1 │ \u001b[1m4\u001b[0m │\n",
       "└─────────────┴───┴───┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of samples: 0\n",
      "Number of NaN in y_true: 0\n",
      "Number of NaN in y_pred: 0\n",
      "Sample of y_pred: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────╮\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Best Prompt:</span> │\n",
       "╰──────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────╮\n",
       "│ \u001b[1;32mBest Prompt:\u001b[0m │\n",
       "╰──────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment. \n",
       "Think through your analysis step by step using chain of thought reasoning. \n",
       "After your analysis, respond with a STRIC JSON dictionary containing two keys: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"chain_of_thought\"</span> <span style=\"font-weight: bold\">(</span>your step-by-step reasoning<span style=\"font-weight: bold\">)</span> and <span style=\"color: #008000; text-decoration-color: #008000\">\"classification\"</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> for positive, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> for negative<span style=\"font-weight: bold\">)</span>.\n",
       "\n",
       "Provide your response as a JSON dictionary with the following structure:\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"chain_of_thought\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Your step-by-step reasoning here\"</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"classification\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> or <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "Ensure that <span style=\"color: #008000; text-decoration-color: #008000\">\"chain_of_thought\"</span> contains your detailed analysis, and <span style=\"color: #008000; text-decoration-color: #008000\">\"classification\"</span> is strictly <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> or <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment. \n",
       "Think through your analysis step by step using chain of thought reasoning. \n",
       "After your analysis, respond with a STRIC JSON dictionary containing two keys: \n",
       "\u001b[32m\"chain_of_thought\"\u001b[0m \u001b[1m(\u001b[0myour step-by-step reasoning\u001b[1m)\u001b[0m and \u001b[32m\"classification\"\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m for positive, \u001b[1;36m0\u001b[0m for negative\u001b[1m)\u001b[0m.\n",
       "\n",
       "Provide your response as a JSON dictionary with the following structure:\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"chain_of_thought\"\u001b[0m: \u001b[32m\"Your step-by-step reasoning here\"\u001b[0m\n",
       "    \u001b[32m\"classification\"\u001b[0m: \u001b[1;36m0\u001b[0m or \u001b[1;36m1\u001b[0m,\n",
       "\u001b[1m}\u001b[0m\n",
       "Ensure that \u001b[32m\"chain_of_thought\"\u001b[0m contains your detailed analysis, and \u001b[32m\"classification\"\u001b[0m is strictly \u001b[1;36m0\u001b[0m or \u001b[1;36m1\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────────────────╮\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Output Format:</span> │\n",
       "╰────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭────────────────╮\n",
       "│ \u001b[1;32mOutput Format:\u001b[0m │\n",
       "╰────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Provide your response as a JSON dictionary with the following structure:\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"chain_of_thought\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Your step-by-step reasoning here\"</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"classification\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> or <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "Ensure that <span style=\"color: #008000; text-decoration-color: #008000\">\"chain_of_thought\"</span> contains your detailed analysis, and <span style=\"color: #008000; text-decoration-color: #008000\">\"classification\"</span> is strictly <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> or <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Provide your response as a JSON dictionary with the following structure:\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"chain_of_thought\"\u001b[0m: \u001b[32m\"Your step-by-step reasoning here\"\u001b[0m\n",
       "    \u001b[32m\"classification\"\u001b[0m: \u001b[1;36m0\u001b[0m or \u001b[1;36m1\u001b[0m,\n",
       "\u001b[1m}\u001b[0m\n",
       "Ensure that \u001b[32m\"chain_of_thought\"\u001b[0m contains your detailed analysis, and \u001b[32m\"classification\"\u001b[0m is strictly \u001b[1;36m0\u001b[0m or \u001b[1;36m1\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                   Comparison of All Iterations                                   </span>\n",
       "┏━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Iteration </span>┃<span style=\"font-weight: bold\"> Precision </span>┃<span style=\"font-weight: bold\"> Recall </span>┃<span style=\"font-weight: bold\"> Accuracy </span>┃<span style=\"font-weight: bold\"> F1-score </span>┃<span style=\"font-weight: bold\"> Valid Predictions </span>┃<span style=\"font-weight: bold\"> Invalid Predictions </span>┃\n",
       "┡━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│     1     │    <span style=\"font-weight: bold\">1.0000</span> │ <span style=\"font-weight: bold\">0.8000</span> │   <span style=\"font-weight: bold\">0.9000</span> │   <span style=\"font-weight: bold\">0.8889</span> │           <span style=\"font-weight: bold\">10.0000</span> │              <span style=\"font-weight: bold\">0.0000</span> │\n",
       "│     2     │    0.6667 │ <span style=\"font-weight: bold\">0.8000</span> │   0.7000 │   0.7273 │           <span style=\"font-weight: bold\">10.0000</span> │              <span style=\"font-weight: bold\">0.0000</span> │\n",
       "└───────────┴───────────┴────────┴──────────┴──────────┴───────────────────┴─────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                   Comparison of All Iterations                                   \u001b[0m\n",
       "┏━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mIteration\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPrecision\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mRecall\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mAccuracy\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mF1-score\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValid Predictions\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mInvalid Predictions\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│     1     │    \u001b[1m1.0000\u001b[0m │ \u001b[1m0.8000\u001b[0m │   \u001b[1m0.9000\u001b[0m │   \u001b[1m0.8889\u001b[0m │           \u001b[1m10.0000\u001b[0m │              \u001b[1m0.0000\u001b[0m │\n",
       "│     2     │    0.6667 │ \u001b[1m0.8000\u001b[0m │   0.7000 │   0.7273 │           \u001b[1m10.0000\u001b[0m │              \u001b[1m0.0000\u001b[0m │\n",
       "└───────────┴───────────┴────────┴──────────┴──────────┴───────────────────┴─────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All logs saved in directory: /Users/danielfiuzadosil/Documents/GitHub/AI-Prompt-Optimiser/examples/binary_classifier/runs/sentiment_exp_Wed_30-Oct-2024_16-18-07\n"
     ]
    }
   ],
   "source": [
    "# Run the prompt optimization process\n",
    "best_prompt, best_metrics = optimize_prompt(\n",
    "    initial_prompt = initial_prompt,\n",
    "    eval_data = eval_data,\n",
    "    iterations = iterations,\n",
    "    eval_provider = eval_provider,\n",
    "    eval_model = eval_model,\n",
    "    eval_temperature = 0.7,\n",
    "    optim_provider = optim_provider,\n",
    "    optim_model = optim_model,\n",
    "    optim_temperature = 0,\n",
    "    use_cache = True,\n",
    "    output_format_prompt = output_format_prompt,\n",
    "    output_schema = output_schema,\n",
    "    fp_comments = fp_comments,\n",
    "    fn_comments = fn_comments,\n",
    "    tp_comments = tp_comments,\n",
    "    invalid_comments = invalid_comments,\n",
    "    prompt_engineering_comments = prompt_engineering_comments,\n",
    "    validation_comments = validation_comments,\n",
    "    experiment_name = experiment_name,\n",
    "    skip_prompt_validation = True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
