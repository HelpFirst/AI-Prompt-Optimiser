{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"test_dashboard_new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_prompt = '''\n",
    "You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment. \n",
    "Think through your analysis step by step using chain of thought reasoning. \n",
    "After your analysis, respond with a STRIC JSON dictionary containing two keys: \n",
    "\"chain_of_thought\" (your step-by-step reasoning) and \"classification\" (1 for positive, 0 for negative).\n",
    "\n",
    "Provide your response as a JSON dictionary with the following structure:\n",
    "{\n",
    "    \"chain_of_thought\": \"Your step-by-step reasoning here\"\n",
    "    \"classification\": 0 or 1,\n",
    "}\n",
    "Ensure that \"chain_of_thought\" contains your detailed analysis, and \"classification\" is strictly 0 or 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output format prompt\n",
    "output_format_prompt = '''\n",
    "Provide your response as a JSON dictionary with the following structure:\n",
    "{\n",
    "    \"chain_of_thought\": \"Your step-by-step reasoning here\"\n",
    "    \"classification\": 0 or 1,\n",
    "}\n",
    "Ensure that \"chain_of_thought\" contains your detailed analysis, and \"classification\" is strictly 0 or 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_comments = \"\"\n",
    "fn_comments = \"\"\n",
    "tp_comments = \"\"\n",
    "invalid_comments = \"\"\n",
    "prompt_engineering_comments = \"\"\n",
    "validation_comments = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output schema\n",
    "output_schema = {\n",
    "    'key_to_extract': 'classification',\n",
    "    'value_mapping': {'1': 1,'0': 0},\n",
    "    'regex_pattern': r'\"classification\":\\s*(\\d)',\n",
    "    #\n",
    "    'chain_of_thought_key': 'chain_of_thought',  \n",
    "    'chain_of_thought_regex': r'\"chain_of_thought\":\\s*\"(.*?)\"',\n",
    "    #\n",
    "    'use_json_mode': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of optimization iterations\n",
    "iterations = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model providers and models for evaluation and optimization\n",
    "eval_provider = \"ollama\"\n",
    "eval_model = \"llama3.1\"\n",
    "optim_provider = \"ollama\"\n",
    "optim_model = \"llama3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the CSV file containing review data for evaluation\n",
    "eval_datapath = \"sentiments.csv\"\n",
    "sample_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to sys.path\n",
    "# Use getcwd() to get the current working directory for Jupyter notebooks\n",
    "current_dir = os.getcwd()\n",
    "grandparent_dir = os.path.dirname(os.path.dirname(current_dir))\n",
    "sys.path.append(grandparent_dir)\n",
    "from src.iterative_prompt_optimization import optimize_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation data shape: (10, 2)\n",
      "                                                text  label\n",
      "0  Was this based on a comic-book? A video-game? ...      1\n",
      "1  If you ask me the first one was really better ...      0\n",
      "2  When I was a kid, I loved \"Tiny Toons\". I espe...      1\n",
      "3  I hate guns and have never murdered anyone, bu...      0\n",
      "4  I do not have much to say than this is a great...      1\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "eval_data = pd.read_csv(eval_datapath, encoding='ISO-8859-1', usecols=['Text', 'Sentiment'])\n",
    "eval_data.columns = ['text', 'label']\n",
    "# Randomly select 50 positive and 50 negative samples\n",
    "eval_data = (\n",
    "    eval_data.groupby('label')\n",
    "    .apply(lambda x: x.sample(n=round(sample_size/2), random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "# Shuffle the DataFrame randomly\n",
    "eval_data = eval_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(f\"Evaluation data shape: {eval_data.shape}\")\n",
    "print(eval_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected evaluation provider: ollama\n",
      "Selected evaluation model: llama3.1\n",
      "Evaluation temperature: 0.7\n",
      "Selected optimization provider: ollama\n",
      "Selected optimization model: llama3.1\n",
      "Optimization temperature: 0\n",
      "Estimated token usage: 111120\n",
      "Estimated cost: $0 API Costs - Running on Local Hardware\n",
      "\n",
      "Do you want to proceed with the optimization? (Y/N): \n",
      "Iteration 1/3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭───────────────────────────────────────────── Current Full Prompt ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Think through your analysis step by step using chain of thought reasoning.                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> After your analysis, respond with a STRIC JSON dictionary containing two keys:                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> \"chain_of_thought\" (your step-by-step reasoning) and \"classification\" (1 for positive, 0 for negative).       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Provide your response as a JSON dictionary with the following structure:                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> {                                                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>     \"chain_of_thought\": \"Your step-by-step reasoning here\"                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>     \"classification\": 0 or 1,                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> }                                                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Ensure that \"chain_of_thought\" contains your detailed analysis, and \"classification\" is strictly 0 or 1       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m────────────────────────────────────────────\u001b[0m\u001b[34m Current Full Prompt \u001b[0m\u001b[34m────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Think through your analysis step by step using chain of thought reasoning.                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m After your analysis, respond with a STRIC JSON dictionary containing two keys:                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \"chain_of_thought\" (your step-by-step reasoning) and \"classification\" (1 for positive, 0 for negative).       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Provide your response as a JSON dictionary with the following structure:                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m {                                                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m     \"chain_of_thought\": \"Your step-by-step reasoning here\"                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m     \"classification\": 0 or 1,                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m }                                                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Ensure that \"chain_of_thought\" contains your detailed analysis, and \"classification\" is strictly 0 or 1       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Processing text 1/10 .....\n"
     ]
    }
   ],
   "source": [
    "# Run the prompt optimization process\n",
    "best_prompt, best_metrics = optimize_prompt(\n",
    "    initial_prompt = initial_prompt,\n",
    "    eval_data = eval_data,\n",
    "    iterations = iterations,\n",
    "    eval_provider = eval_provider,\n",
    "    eval_model = eval_model,\n",
    "    eval_temperature = 0.7,\n",
    "    optim_provider = optim_provider,\n",
    "    optim_model = optim_model,\n",
    "    optim_temperature = 0,\n",
    "    use_cache = True,\n",
    "    output_format_prompt = output_format_prompt,\n",
    "    output_schema = output_schema,\n",
    "    fp_comments = fp_comments,\n",
    "    fn_comments = fn_comments,\n",
    "    tp_comments = tp_comments,\n",
    "    invalid_comments = invalid_comments,\n",
    "    prompt_engineering_comments = prompt_engineering_comments,\n",
    "    validation_comments = validation_comments,\n",
    "    experiment_name = experiment_name,\n",
    "    skip_prompt_validation = True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
