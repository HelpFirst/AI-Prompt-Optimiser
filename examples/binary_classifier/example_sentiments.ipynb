{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"sentiment_exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_prompt = '''\n",
    "You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment. \n",
    "Think through your analysis step by step using chain of thought reasoning. \n",
    "After your analysis, respond with a STRIC JSON dictionary containing two keys: \n",
    "\"chain_of_thought\" (your step-by-step reasoning) and \"classification\" (1 for positive, 0 for negative).\n",
    "\n",
    "Provide your response as a JSON dictionary with the following structure:\n",
    "{\n",
    "    \"chain_of_thought\": \"Your step-by-step reasoning here\"\n",
    "    \"classification\": 0 or 1,\n",
    "}\n",
    "Ensure that \"chain_of_thought\" contains your detailed analysis, and \"classification\" is strictly 0 or 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output format prompt\n",
    "output_format_prompt = '''\n",
    "Provide your response as a JSON dictionary with the following structure:\n",
    "{\n",
    "    \"chain_of_thought\": \"Your step-by-step reasoning here\"\n",
    "    \"classification\": 0 or 1,\n",
    "}\n",
    "Ensure that \"chain_of_thought\" contains your detailed analysis, and \"classification\" is strictly 0 or 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_comments = \"\"\n",
    "fn_comments = \"\"\n",
    "tp_comments = \"\"\n",
    "invalid_comments = \"\"\n",
    "prompt_engineering_comments = \"\"\n",
    "validation_comments = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output schema\n",
    "output_schema = {\n",
    "    'key_to_extract': 'classification',\n",
    "    'value_mapping': {'1': 1,'0': 0},\n",
    "    'regex_pattern': r'\"classification\":\\s*(\\d)',\n",
    "    #\n",
    "    'chain_of_thought_key': 'chain_of_thought',  \n",
    "    'chain_of_thought_regex': r'\"chain_of_thought\":\\s*\"(.*?)\"',\n",
    "    #\n",
    "    'use_json_mode': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of optimization iterations\n",
    "iterations = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model providers and models for evaluation and optimization\n",
    "# eval_provider = \"ollama\"\n",
    "# eval_model = \"llama3.1\"\n",
    "# optim_provider = \"ollama\"\n",
    "# optim_model = \"llama3.1\"\n",
    "eval_provider = \"openai\"\n",
    "eval_model = \"gpt-4o-mini\"\n",
    "optim_provider = \"openai\"\n",
    "optim_model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the CSV file containing review data for evaluation\n",
    "eval_datapath = \"sentiments.csv\"\n",
    "sample_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to sys.path\n",
    "# Use getcwd() to get the current working directory for Jupyter notebooks\n",
    "current_dir = os.getcwd()\n",
    "grandparent_dir = os.path.dirname(os.path.dirname(current_dir))\n",
    "sys.path.append(grandparent_dir)\n",
    "from src import optimize_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation data shape: (10, 2)\n",
      "                                                text  label\n",
      "0  Was this based on a comic-book? A video-game? ...      1\n",
      "1  If you ask me the first one was really better ...      0\n",
      "2  When I was a kid, I loved \"Tiny Toons\". I espe...      1\n",
      "3  I hate guns and have never murdered anyone, bu...      0\n",
      "4  I do not have much to say than this is a great...      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/w_c5c0zs70lcg80xwzft9fjh0000gn/T/ipykernel_24687/3552288940.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=round(sample_size/2), random_state=42))\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "eval_data = pd.read_csv(eval_datapath, encoding='ISO-8859-1', usecols=['Text', 'Sentiment'])\n",
    "eval_data.columns = ['text', 'label']\n",
    "# Randomly select 50 positive and 50 negative samples\n",
    "eval_data = (\n",
    "    eval_data.groupby('label')\n",
    "    .apply(lambda x: x.sample(n=round(sample_size/2), random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "# Shuffle the DataFrame randomly\n",
    "eval_data = eval_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(f\"Evaluation data shape: {eval_data.shape}\")\n",
    "print(eval_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected problem type: binary\n",
      "Selected evaluation provider: openai\n",
      "Selected evaluation model: gpt-4o-mini\n",
      "Evaluation temperature: 0.7\n",
      "Selected optimization provider: openai\n",
      "Selected optimization model: gpt-4o-mini\n",
      "Optimization temperature: 0\n",
      "Estimated token usage: 74080\n",
      "Estimated cost: $0.09\n",
      "\n",
      "Do you want to proceed with the optimization? (Y/N): \n",
      "Iteration 1/2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭───────────────────────────────────────────── Current Full Prompt ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Think through your analysis step by step using chain of thought reasoning.                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> After your analysis, respond with a STRIC JSON dictionary containing two keys:                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> \"chain_of_thought\" (your step-by-step reasoning) and \"classification\" (1 for positive, 0 for negative).       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Provide your response as a JSON dictionary with the following structure:                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> {                                                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>     \"chain_of_thought\": \"Your step-by-step reasoning here\"                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>     \"classification\": 0 or 1,                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> }                                                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Ensure that \"chain_of_thought\" contains your detailed analysis, and \"classification\" is strictly 0 or 1       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m────────────────────────────────────────────\u001b[0m\u001b[34m Current Full Prompt \u001b[0m\u001b[34m────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Think through your analysis step by step using chain of thought reasoning.                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m After your analysis, respond with a STRIC JSON dictionary containing two keys:                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \"chain_of_thought\" (your step-by-step reasoning) and \"classification\" (1 for positive, 0 for negative).       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Provide your response as a JSON dictionary with the following structure:                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m {                                                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m     \"chain_of_thought\": \"Your step-by-step reasoning here\"                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m     \"classification\": 0 or 1,                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m }                                                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Ensure that \"chain_of_thought\" contains your detailed analysis, and \"classification\" is strictly 0 or 1       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Processing text 1/10 .....\n",
      "Using cached output for text 1/10\n",
      "Prediction 1/10: 0 | Ground Truth: 1 ❌ (FN)\n",
      "-----------------------------------\n",
      "Processing text 2/10 .....\n",
      "Using cached output for text 2/10\n",
      "Prediction 2/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "-----------------------------------\n",
      "Processing text 3/10 .....\n",
      "Using cached output for text 3/10\n",
      "Prediction 3/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "-----------------------------------\n",
      "Processing text 4/10 .....\n",
      "Using cached output for text 4/10\n",
      "Prediction 4/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "-----------------------------------\n",
      "Processing text 5/10 .....\n",
      "Using cached output for text 5/10\n",
      "Prediction 5/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "-----------------------------------\n",
      "Processing text 6/10 .....\n",
      "Using cached output for text 6/10\n",
      "Prediction 6/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "-----------------------------------\n",
      "Processing text 7/10 .....\n",
      "Using cached output for text 7/10\n",
      "Prediction 7/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "-----------------------------------\n",
      "Processing text 8/10 .....\n",
      "Using cached output for text 8/10\n",
      "Prediction 8/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "-----------------------------------\n",
      "Processing text 9/10 .....\n",
      "Using cached output for text 9/10\n",
      "Prediction 9/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "-----------------------------------\n",
      "Processing text 10/10 .....\n",
      "Using cached output for text 10/10\n",
      "Prediction 10/10: 1 | Ground Truth: 1 ✅ (TP)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 1</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 1.0000 │\n",
       "│ Recall              │ 0.8000 │\n",
       "│ Accuracy            │ 0.9000 │\n",
       "│ F1-score            │ 0.8889 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├─────────────────────┼────────┤\n",
       "│ Valid Predictions   │     10 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 1\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 1.0000 │\n",
       "│ Recall              │ 0.8000 │\n",
       "│ Accuracy            │ 0.9000 │\n",
       "│ F1-score            │ 0.8889 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m                   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m      \u001b[0m\u001b[2m \u001b[0m│\n",
       "├─────────────────────┼────────┤\n",
       "│ Valid Predictions   │     10 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">   Confusion Matrix    </span>\n",
       "┏━━━━━━━━━━━━━┳━━━┳━━━┓\n",
       "┃<span style=\"font-weight: bold\"> True↓/Pred→ </span>┃<span style=\"font-weight: bold\"> 0 </span>┃<span style=\"font-weight: bold\"> 1 </span>┃\n",
       "┡━━━━━━━━━━━━━╇━━━╇━━━┩\n",
       "│ 0           │ <span style=\"font-weight: bold\">5</span> │ 0 │\n",
       "├─────────────┼───┼───┤\n",
       "│ 1           │ 1 │ <span style=\"font-weight: bold\">4</span> │\n",
       "└─────────────┴───┴───┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m   Confusion Matrix    \u001b[0m\n",
       "┏━━━━━━━━━━━━━┳━━━┳━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTrue↓/Pred→\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m0\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m1\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━╇━━━╇━━━┩\n",
       "│ 0           │ \u001b[1m5\u001b[0m │ 0 │\n",
       "├─────────────┼───┼───┤\n",
       "│ 1           │ 1 │ \u001b[1m4\u001b[0m │\n",
       "└─────────────┴───┴───┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Analyzing misclassifications, true positives, and invalid outputs...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭───────── False Positives Analysis ──────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> No false positives found in this iteration. <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m────────\u001b[0m\u001b[1m False Positives Analysis \u001b[0m\u001b[1m─────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m No false positives found in this iteration. \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭─────────────────────────────────────────── False Negatives Analysis ────────────────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Overemphasis on Negative Language**: The chain of thought heavily focuses on the negative aspects of the   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> film, such as \"nothing to be taken seriously,\" \"dumb,\" and \"awful.\" This leads to a misclassification of the    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> overall sentiment. To improve recall, the classifier should be trained to recognize nuanced expressions of      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> enjoyment or entertainment, even when accompanied by critical language.                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Contextual Interpretation of Humor**: The text mentions \"mindless fun\" and \"unintentional humor,\" which    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> can indicate a positive sentiment despite the surrounding criticism. The classifier should be enhanced to       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> identify contextually positive phrases that may be overshadowed by negative descriptors, allowing for a more    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> balanced sentiment assessment.                                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Recognition of Mixed Sentiment**: The review contains elements of mixed sentiment, where the reviewer      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> acknowledges some entertaining aspects of the film amidst the criticism. The classifier should be adjusted to   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> better handle mixed sentiments, possibly by implementing a multi-class classification approach that can         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> distinguish between purely negative, purely positive, and mixed sentiments.                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Weighting of Positive Phrases**: Phrases like \"exciting and fun\" and \"spectacular and excellently shot\"    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> should carry more weight in the sentiment analysis. The model could benefit from a weighting system that        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> elevates the significance of positive phrases, even when they are surrounded by negative commentary.            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 5. **Improved Training Data**: Incorporating more examples of reviews that express mixed sentiments or critical <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> yet appreciative tones could help the classifier learn to identify positive sentiments in complex reviews. This <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> would enhance its ability to discern when a review, despite its critical nature, still conveys a positive       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> sentiment overall.                                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m──────────────────────────────────────────\u001b[0m\u001b[1m False Negatives Analysis \u001b[0m\u001b[1m───────────────────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Overemphasis on Negative Language**: The chain of thought heavily focuses on the negative aspects of the   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m film, such as \"nothing to be taken seriously,\" \"dumb,\" and \"awful.\" This leads to a misclassification of the    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m overall sentiment. To improve recall, the classifier should be trained to recognize nuanced expressions of      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m enjoyment or entertainment, even when accompanied by critical language.                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Contextual Interpretation of Humor**: The text mentions \"mindless fun\" and \"unintentional humor,\" which    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m can indicate a positive sentiment despite the surrounding criticism. The classifier should be enhanced to       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m identify contextually positive phrases that may be overshadowed by negative descriptors, allowing for a more    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m balanced sentiment assessment.                                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Recognition of Mixed Sentiment**: The review contains elements of mixed sentiment, where the reviewer      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m acknowledges some entertaining aspects of the film amidst the criticism. The classifier should be adjusted to   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m better handle mixed sentiments, possibly by implementing a multi-class classification approach that can         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m distinguish between purely negative, purely positive, and mixed sentiments.                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Weighting of Positive Phrases**: Phrases like \"exciting and fun\" and \"spectacular and excellently shot\"    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m should carry more weight in the sentiment analysis. The model could benefit from a weighting system that        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m elevates the significance of positive phrases, even when they are surrounded by negative commentary.            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 5. **Improved Training Data**: Incorporating more examples of reviews that express mixed sentiments or critical \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m yet appreciative tones could help the classifier learn to identify positive sentiments in complex reviews. This \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m would enhance its ability to discern when a review, despite its critical nature, still conveys a positive       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m sentiment overall.                                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭──────────────────────────────────────────── True Positives Analysis ────────────────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Use of Positive Language**: All true positive examples prominently feature positive language and           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> descriptors. Phrases like \"loved,\" \"great,\" \"amazing,\" and \"excellent quality\" are clear indicators of positive <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> sentiment. Reinforcing the identification of such language in the training data can enhance classification      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> accuracy.                                                                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Emotional Engagement**: The texts convey strong emotional engagement and personal connection to the        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> subject matter. Expressions of nostalgia, enjoyment, and appreciation (e.g., \"I was still on the floors         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> laughing,\" \"I loved every second\") signal positive sentiment. Training the model to recognize emotional cues    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> can improve its sensitivity to sentiment.                                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **High Ratings and Recommendations**: The presence of numerical ratings (e.g., \"10/10,\" \"9 out of 10 stars\") <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> and explicit recommendations (e.g., \"I recommend that it is shown\") serve as strong indicators of positive      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> sentiment. Incorporating a feature that emphasizes the significance of ratings and recommendations could        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> bolster classification confidence.                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Contextual Understanding**: The reviews provide context that enhances the positive sentiment, such as      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> discussing the quality of performances or the impact of the film. Training the model to consider context and    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> the overall message can help differentiate between nuanced sentiments.                                          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 5. **Consistent Themes of Praise**: Each true positive example consistently emphasizes themes of praise and     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> appreciation throughout the text. Encouraging the model to identify and weigh recurring positive themes can     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> lead to more accurate sentiment classifications.                                                                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> By focusing on these key elements, the sentiment analysis classifier can improve its ability to accurately      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> identify positive sentiments in various texts.                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m───────────────────────────────────────────\u001b[0m\u001b[1m True Positives Analysis \u001b[0m\u001b[1m───────────────────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Use of Positive Language**: All true positive examples prominently feature positive language and           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m descriptors. Phrases like \"loved,\" \"great,\" \"amazing,\" and \"excellent quality\" are clear indicators of positive \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m sentiment. Reinforcing the identification of such language in the training data can enhance classification      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m accuracy.                                                                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Emotional Engagement**: The texts convey strong emotional engagement and personal connection to the        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m subject matter. Expressions of nostalgia, enjoyment, and appreciation (e.g., \"I was still on the floors         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m laughing,\" \"I loved every second\") signal positive sentiment. Training the model to recognize emotional cues    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m can improve its sensitivity to sentiment.                                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **High Ratings and Recommendations**: The presence of numerical ratings (e.g., \"10/10,\" \"9 out of 10 stars\") \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m and explicit recommendations (e.g., \"I recommend that it is shown\") serve as strong indicators of positive      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m sentiment. Incorporating a feature that emphasizes the significance of ratings and recommendations could        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m bolster classification confidence.                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Contextual Understanding**: The reviews provide context that enhances the positive sentiment, such as      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m discussing the quality of performances or the impact of the film. Training the model to consider context and    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m the overall message can help differentiate between nuanced sentiments.                                          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 5. **Consistent Themes of Praise**: Each true positive example consistently emphasizes themes of praise and     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m appreciation throughout the text. Encouraging the model to identify and weigh recurring positive themes can     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m lead to more accurate sentiment classifications.                                                                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m By focusing on these key elements, the sentiment analysis classifier can improve its ability to accurately      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m identify positive sentiments in various texts.                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭───────── Invalid Outputs Analysis ──────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> No invalid outputs found in this iteration. <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m────────\u001b[0m\u001b[1m Invalid Outputs Analysis \u001b[0m\u001b[1m─────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m No invalid outputs found in this iteration. \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 0\n",
      "Number of NaN in y_true: 0\n",
      "Number of NaN in y_pred: 0\n",
      "Sample of y_pred: []\n",
      "\n",
      "Iteration 2/2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────────── Current Full Prompt ──────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Use chain of thought reasoning to analyze the text step by step, focusing on identifying positive language,     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> emotional engagement, ratings, and contextual understanding. Be aware of mixed sentiments and recognize that    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> positive phrases can exist alongside negative descriptors. After your analysis, respond with a strict JSON      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> dictionary containing two keys: \"chain_of_thought\" (your detailed reasoning) and \"classification\" (1 for        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> positive, 0 for negative).                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Provide your response as a JSON dictionary with the following structure:                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> {                                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>     \"chain_of_thought\": \"Your step-by-step reasoning here\",                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>     \"classification\": 0 or 1                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> }                                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Ensure that \"chain_of_thought\" contains your detailed analysis, and \"classification\" is strictly 0 or 1.        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m Current Full Prompt \u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Use chain of thought reasoning to analyze the text step by step, focusing on identifying positive language,     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m emotional engagement, ratings, and contextual understanding. Be aware of mixed sentiments and recognize that    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m positive phrases can exist alongside negative descriptors. After your analysis, respond with a strict JSON      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m dictionary containing two keys: \"chain_of_thought\" (your detailed reasoning) and \"classification\" (1 for        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m positive, 0 for negative).                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Provide your response as a JSON dictionary with the following structure:                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m {                                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m     \"chain_of_thought\": \"Your step-by-step reasoning here\",                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m     \"classification\": 0 or 1                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m }                                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Ensure that \"chain_of_thought\" contains your detailed analysis, and \"classification\" is strictly 0 or 1.        \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Processing text 1/10 .....\n",
      "Prediction 1/10: 0 | Ground Truth: 1 ❌ (FN)\n",
      "-----------------------------------\n",
      "Processing text 2/10 .....\n",
      "Prediction 2/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "-----------------------------------\n",
      "Processing text 3/10 .....\n",
      "Prediction 3/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "-----------------------------------\n",
      "Processing text 4/10 .....\n",
      "Prediction 4/10: 1 | Ground Truth: 0 ❌ (FP)\n",
      "-----------------------------------\n",
      "Processing text 5/10 .....\n",
      "Prediction 5/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "-----------------------------------\n",
      "Processing text 6/10 .....\n",
      "Prediction 6/10: 1 | Ground Truth: 0 ❌ (FP)\n",
      "-----------------------------------\n",
      "Processing text 7/10 .....\n",
      "Prediction 7/10: 1 | Ground Truth: 1 ✅ (TP)\n",
      "-----------------------------------\n",
      "Processing text 8/10 .....\n",
      "Prediction 8/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "-----------------------------------\n",
      "Processing text 9/10 .....\n",
      "Prediction 9/10: 0 | Ground Truth: 0 ✅ (TN)\n",
      "-----------------------------------\n",
      "Processing text 10/10 .....\n",
      "Prediction 10/10: 1 | Ground Truth: 1 ✅ (TP)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 2</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.6667 │\n",
       "│ Recall              │ 0.8000 │\n",
       "│ Accuracy            │ 0.7000 │\n",
       "│ F1-score            │ 0.7273 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├─────────────────────┼────────┤\n",
       "│ Valid Predictions   │     10 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 2\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.6667 │\n",
       "│ Recall              │ 0.8000 │\n",
       "│ Accuracy            │ 0.7000 │\n",
       "│ F1-score            │ 0.7273 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m                   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m      \u001b[0m\u001b[2m \u001b[0m│\n",
       "├─────────────────────┼────────┤\n",
       "│ Valid Predictions   │     10 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">   Confusion Matrix    </span>\n",
       "┏━━━━━━━━━━━━━┳━━━┳━━━┓\n",
       "┃<span style=\"font-weight: bold\"> True↓/Pred→ </span>┃<span style=\"font-weight: bold\"> 0 </span>┃<span style=\"font-weight: bold\"> 1 </span>┃\n",
       "┡━━━━━━━━━━━━━╇━━━╇━━━┩\n",
       "│ 0           │ <span style=\"font-weight: bold\">3</span> │ 2 │\n",
       "├─────────────┼───┼───┤\n",
       "│ 1           │ 1 │ <span style=\"font-weight: bold\">4</span> │\n",
       "└─────────────┴───┴───┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m   Confusion Matrix    \u001b[0m\n",
       "┏━━━━━━━━━━━━━┳━━━┳━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTrue↓/Pred→\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m0\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m1\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━╇━━━╇━━━┩\n",
       "│ 0           │ \u001b[1m3\u001b[0m │ 2 │\n",
       "├─────────────┼───┼───┤\n",
       "│ 1           │ 1 │ \u001b[1m4\u001b[0m │\n",
       "└─────────────┴───┴───┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of samples: 0\n",
      "Number of NaN in y_true: 0\n",
      "Number of NaN in y_pred: 0\n",
      "Sample of y_pred: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────╮\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Best Prompt:</span> │\n",
       "╰──────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────╮\n",
       "│ \u001b[1;32mBest Prompt:\u001b[0m │\n",
       "╰──────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment. \n",
       "Think through your analysis step by step using chain of thought reasoning. \n",
       "After your analysis, respond with a STRIC JSON dictionary containing two keys: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"chain_of_thought\"</span> <span style=\"font-weight: bold\">(</span>your step-by-step reasoning<span style=\"font-weight: bold\">)</span> and <span style=\"color: #008000; text-decoration-color: #008000\">\"classification\"</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> for positive, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> for negative<span style=\"font-weight: bold\">)</span>.\n",
       "\n",
       "Provide your response as a JSON dictionary with the following structure:\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"chain_of_thought\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Your step-by-step reasoning here\"</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"classification\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> or <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "Ensure that <span style=\"color: #008000; text-decoration-color: #008000\">\"chain_of_thought\"</span> contains your detailed analysis, and <span style=\"color: #008000; text-decoration-color: #008000\">\"classification\"</span> is strictly <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> or <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment. \n",
       "Think through your analysis step by step using chain of thought reasoning. \n",
       "After your analysis, respond with a STRIC JSON dictionary containing two keys: \n",
       "\u001b[32m\"chain_of_thought\"\u001b[0m \u001b[1m(\u001b[0myour step-by-step reasoning\u001b[1m)\u001b[0m and \u001b[32m\"classification\"\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m for positive, \u001b[1;36m0\u001b[0m for negative\u001b[1m)\u001b[0m.\n",
       "\n",
       "Provide your response as a JSON dictionary with the following structure:\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"chain_of_thought\"\u001b[0m: \u001b[32m\"Your step-by-step reasoning here\"\u001b[0m\n",
       "    \u001b[32m\"classification\"\u001b[0m: \u001b[1;36m0\u001b[0m or \u001b[1;36m1\u001b[0m,\n",
       "\u001b[1m}\u001b[0m\n",
       "Ensure that \u001b[32m\"chain_of_thought\"\u001b[0m contains your detailed analysis, and \u001b[32m\"classification\"\u001b[0m is strictly \u001b[1;36m0\u001b[0m or \u001b[1;36m1\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────────────────╮\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Output Format:</span> │\n",
       "╰────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭────────────────╮\n",
       "│ \u001b[1;32mOutput Format:\u001b[0m │\n",
       "╰────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Provide your response as a JSON dictionary with the following structure:\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"chain_of_thought\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Your step-by-step reasoning here\"</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"classification\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> or <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "Ensure that <span style=\"color: #008000; text-decoration-color: #008000\">\"chain_of_thought\"</span> contains your detailed analysis, and <span style=\"color: #008000; text-decoration-color: #008000\">\"classification\"</span> is strictly <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> or <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Provide your response as a JSON dictionary with the following structure:\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"chain_of_thought\"\u001b[0m: \u001b[32m\"Your step-by-step reasoning here\"\u001b[0m\n",
       "    \u001b[32m\"classification\"\u001b[0m: \u001b[1;36m0\u001b[0m or \u001b[1;36m1\u001b[0m,\n",
       "\u001b[1m}\u001b[0m\n",
       "Ensure that \u001b[32m\"chain_of_thought\"\u001b[0m contains your detailed analysis, and \u001b[32m\"classification\"\u001b[0m is strictly \u001b[1;36m0\u001b[0m or \u001b[1;36m1\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                   Comparison of All Iterations                                   </span>\n",
       "┏━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Iteration </span>┃<span style=\"font-weight: bold\"> Precision </span>┃<span style=\"font-weight: bold\"> Recall </span>┃<span style=\"font-weight: bold\"> Accuracy </span>┃<span style=\"font-weight: bold\"> F1-score </span>┃<span style=\"font-weight: bold\"> Valid Predictions </span>┃<span style=\"font-weight: bold\"> Invalid Predictions </span>┃\n",
       "┡━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│     1     │    <span style=\"font-weight: bold\">1.0000</span> │ <span style=\"font-weight: bold\">0.8000</span> │   <span style=\"font-weight: bold\">0.9000</span> │   <span style=\"font-weight: bold\">0.8889</span> │           <span style=\"font-weight: bold\">10.0000</span> │              <span style=\"font-weight: bold\">0.0000</span> │\n",
       "│     2     │    0.6667 │ <span style=\"font-weight: bold\">0.8000</span> │   0.7000 │   0.7273 │           <span style=\"font-weight: bold\">10.0000</span> │              <span style=\"font-weight: bold\">0.0000</span> │\n",
       "└───────────┴───────────┴────────┴──────────┴──────────┴───────────────────┴─────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                   Comparison of All Iterations                                   \u001b[0m\n",
       "┏━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mIteration\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPrecision\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mRecall\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mAccuracy\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mF1-score\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValid Predictions\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mInvalid Predictions\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│     1     │    \u001b[1m1.0000\u001b[0m │ \u001b[1m0.8000\u001b[0m │   \u001b[1m0.9000\u001b[0m │   \u001b[1m0.8889\u001b[0m │           \u001b[1m10.0000\u001b[0m │              \u001b[1m0.0000\u001b[0m │\n",
       "│     2     │    0.6667 │ \u001b[1m0.8000\u001b[0m │   0.7000 │   0.7273 │           \u001b[1m10.0000\u001b[0m │              \u001b[1m0.0000\u001b[0m │\n",
       "└───────────┴───────────┴────────┴──────────┴──────────┴───────────────────┴─────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All logs saved in directory: /Users/danielfiuzadosil/Documents/GitHub/AI-Prompt-Optimiser/examples/binary_classifier/runs/sentiment_exp_Mon_25-Nov-2024_13-45-00\n"
     ]
    }
   ],
   "source": [
    "# Run the prompt optimization process\n",
    "best_prompt, best_metrics = optimize_prompt(\n",
    "    initial_prompt = initial_prompt,\n",
    "    eval_data = eval_data,\n",
    "    iterations = iterations,\n",
    "    eval_provider = eval_provider,\n",
    "    eval_model = eval_model,\n",
    "    eval_temperature = 0.7,\n",
    "    optim_provider = optim_provider,\n",
    "    optim_model = optim_model,\n",
    "    optim_temperature = 0,\n",
    "    use_cache = True,\n",
    "    output_format_prompt = output_format_prompt,\n",
    "    output_schema = output_schema,\n",
    "    fp_comments = fp_comments,\n",
    "    fn_comments = fn_comments,\n",
    "    tp_comments = tp_comments,\n",
    "    invalid_comments = invalid_comments,\n",
    "    prompt_engineering_comments = prompt_engineering_comments,\n",
    "    validation_comments = validation_comments,\n",
    "    experiment_name = experiment_name,\n",
    "    skip_prompt_validation = True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
