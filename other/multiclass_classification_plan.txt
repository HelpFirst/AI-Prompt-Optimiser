Summary of Changes:
1. Modify input handling and problem type detection in optimize.py
2. Update evaluation metrics calculation in evaluation.py
3. Adjust prompt generation process in prompt_generation.py
4. Enhance dashboard generation in dashboard_generator.py
5. Update main optimization loop in optimize.py
6. Modify example notebooks for both binary and multiclass classification
7. Update configuration, utility functions, and HTML templates
8. Implement testing, documentation updates, and optional enhancements

Step 1: Modify input handling and problem type detection
File: src/iterative_prompt_optimization/optimize.py

1.1. Add a function to detect the problem type:

```python
def detect_problem_type(eval_data, output_schema):
    unique_labels = eval_data['label'].nunique()
    value_mapping_length = len(output_schema['value_mapping'])
    
    if unique_labels > 2 or value_mapping_length > 2:
        return 'multiclass'
    else:
        return 'binary'
```

1.2. Update the optimize_prompt function signature and add problem type detection:

```python
def optimize_prompt(initial_prompt, output_format_prompt, eval_data, iterations, ..., problem_type=None):
    # Existing code...
    
    if problem_type is None:
        problem_type = detect_problem_type(eval_data, output_schema)
    print(f"Detected problem type: {problem_type}")
    
    # Pass problem_type to other functions
    # ...
```

Step 2: Update evaluation metrics calculation
File: src/iterative_prompt_optimization/evaluation.py

2.1. Modify the calculate_metrics function:

```python
def calculate_metrics(predictions, true_labels, invalid_predictions, valid_predictions, false_positives, false_negatives, true_positives, invalid_outputs, problem_type):
    if len(predictions) > 0:
        if problem_type == 'binary':
            precision = precision_score(true_labels, predictions, zero_division=0)
            recall = recall_score(true_labels, predictions, zero_division=0)
            f1 = f1_score(true_labels, predictions, zero_division=0)
        else:  # multiclass
            precision = precision_score(true_labels, predictions, average='weighted', zero_division=0)
            recall = recall_score(true_labels, predictions, average='weighted', zero_division=0)
            f1 = f1_score(true_labels, predictions, average='weighted', zero_division=0)
        
        accuracy = accuracy_score(true_labels, predictions)
    else:
        precision = recall = f1 = accuracy = 0.0

    # Rest of the function remains the same
    # ...
```

2.2. Update the evaluate_prompt function:

```python
def evaluate_prompt(full_prompt, eval_data, output_schema, log_dir=None, iteration=None, use_cache=True, provider=None, model=None, temperature=0.7, problem_type='binary'):
    # Existing code...
    
    results = calculate_metrics(predictions, true_labels, invalid_predictions, valid_predictions, false_positives, false_negatives, true_positives, invalid_outputs, problem_type)
    
    # Rest of the function remains the same
    # ...
```

Step 3: Adjust prompt generation process
File: src/iterative_prompt_optimization/prompt_generation.py

3.1. Update the generate_new_prompt function:

```python
def generate_new_prompt(initial_prompt, output_format_prompt, false_positives, false_negatives, true_positives, invalid_outputs, previous_metrics, log_dir=None, iteration=None, provider=None, model=None, temperature=0.9, fp_comments="", fn_comments="", tp_comments="", invalid_comments="", prompt_engineering_comments="", problem_type='binary'):
    # Existing code...
    
    prompt_engineer_input = config.PROMPT_ENGINEER_INPUT.format(
        # Existing parameters...
        problem_type=problem_type
    )
    
    # Rest of the function remains the same
    # ...
```

Step 4: Enhance dashboard generation
File: src/iterative_prompt_optimization/dashboard_generator.py

4.1. Modify the generate_confusion_matrix function:

```python
def generate_confusion_matrix(y_true, y_pred, problem_type):
    cm = confusion_matrix(y_true, y_pred)
    
    if problem_type == 'multiclass':
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd')
        plt.title('Multiclass Confusion Matrix')
    else:
        # Existing binary confusion matrix code
    
    # Rest of the function remains the same
    # ...
```

4.2. Update the generate_combined_dashboard function:

```python
def generate_combined_dashboard(log_dir, all_metrics, best_prompt, output_format_prompt, problem_type):
    # Existing code...
    
    html_content = template.render(
        # Existing parameters...
        problem_type=problem_type
    )
    
    # Rest of the function remains the same
    # ...
```

Step 5: Update main optimization loop
File: src/iterative_prompt_optimization/optimize.py

5.1. Modify the optimize_prompt function to pass problem_type:

```python
def optimize_prompt(initial_prompt, output_format_prompt, eval_data, iterations, ...):
    # Existing code...
    
    problem_type = detect_problem_type(eval_data, output_schema)
    
    for i in range(iterations):
        # Existing code...
        
        results = evaluate_prompt(current_prompt, eval_data, output_schema, log_dir, i+1, use_cache, eval_provider, eval_model, eval_temperature, problem_type)
        
        # Existing code...
        
        new_prompt, analyses, prompts_used = generate_new_prompt(
            # Existing parameters...
            problem_type=problem_type
        )
        
        # Existing code...
    
    generate_combined_dashboard(log_dir, all_metrics, best_prompt, output_format_prompt, problem_type)
    
    # Rest of the function remains the same
    # ...
```

Step 6: Modify example notebooks
6.1. Update existing binary classification example (e.g., example_sentiments.ipynb)
6.2. Create or update multiclass classification example (e.g., example_emotions.ipynb)

For the multiclass example, update the output schema, initial prompt, and evaluation data as shown in the previous plan.

Step 7: Update configuration and utility functions
7.1. Review and update config.py to include any necessary changes for multiclass support
7.2. Update utility functions in utils.py if needed

Step 8: Testing, Documentation, and Optional Enhancements
8.1. Implement tests for both binary and multiclass scenarios
8.2. Update README.md and other documentation
8.3. Consider implementing optional enhancements like multiclass confusion matrix visualization and class-specific metrics

By following this updated plan, the AI Prompt Optimizer will support both binary and multiclass classification problems effectively.
